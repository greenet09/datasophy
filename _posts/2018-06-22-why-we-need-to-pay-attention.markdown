---
layout: post
title:  "Why should we care about companies collecting our data?"
date:   2018-06-22 19:00
categories: 
---
<h2>Big data and machine learning is ubiquitous</h2>
In 2018, big data is everywhere. As chronicled in several recently-published books (check out Cathy O'Neil's "Weapons of Math Destruction," for example) about the ubiquity of algorithmic decision making in modern society, our countless daily interactions with internet-based products and services are constantly being controlled, shaped, and personalized via faceless  algorithms. Almost everything we do on the internet leaves a potential “digital footprint” that can be traced, analyzed and aggregated together with the footprints of millions of others. With enough of these digital traces, machine learning algorithms can be used to infer, with remarkable accuracy, psychological profiles and personality traits. For behavioral scientists as well as data scientists, this massive amount of human-centered data represents a novel data source for conducting research, filled with potential new insights into human behavior. For businesses, behavioral big data offers managers a chance to make data-driven decisions to influence company policy and strategy where they had previously relied on personal experience, gut-feeling, and anecdote. In short, the use of behavioral big data is firmly entrenched into modern society and is already changing the way we do business and interact with products and services.

<h2>Behavior big data lets advertisers target you better than ever</h2>
In the areas of marketing and advertising, big data on users allows technology-savvy firms to micro-target audiences with specific products and services. It is no surprise—though it certainly would have been to Mark Zuckerberg in 2004—that the tech giants Google and Facebook have completely disrupted the market research industry and are expected to displace the “old guard” by 2020.  To cope with industry demand for data, a new cottage industry of “data brokers”—companies that act as repositories of consumer demographic and behavioral information with the goal of selling these data to other companies—has cropped up. One of the largest data brokers, Acxiom, reported over $800M in revenues in 2015 and has partnered up with Facebook to provide them with demographic and behavioral data on users in the USA, Germany, France, and the UK.

<h2>In the US, support for regulation actually seems to be decreasing</h2>
Despite all the ways in which the average citizen’s life has increasingly been affected by these technological developments, relatively little has been done by governments to regulate this new economic environment borne out of the burgeoning “data economy.” In the USA, for example, industries that utilize “sensitive” data on individuals, such as financial institutions and healthcare organizations, or industries that pose risks to individuals, such as the pharmaceutical industry, have federal laws regulating the collection and storage of sensitive data (cf. HIPAA for health care data and the Fair Credit Reporting Act ). Yet similar federal laws regulating Google, Facebook, and Amazon, who also control vast stores of potentially sensitive personal data on their hundreds of millions of users, have never been passed in Congress. Basic methods of data collection, storage, and analysis have mostly been left untouched by regulatory hands, in favor of self-regulation and a complicated web of industry “best practices”. In 2017, for example, Donald Trump signed a bill repealing the Obama-era FCC Privacy Rule, which would have required broadband ISP providers to obtain consent before collecting and using browsing history and app usage, which was previously deemed “sensitive information.”  Some analysts were then left to speculate that the FCC Privacy Rule was repealed in order to allow large ISPs to compete with the data-rich Silicon Valley tech giants in the $83B digital advertising space.

<h2>Why are we here now?</h2>
 Part of the problem is that technological innovation has far outpaced legal, social, and ethical innovation. By the time society has adapted to a new technology, another, newer technology has already superseded it. This process has manifested itself in a common refrain seen in academic papers on big data and the internet of things (IoT) that the time is ripe for society-wide debate on the “future values of living” and that technology corporations should not have first-mover advantage in these important society-wide ethical and legal debates.
 
<h2>Europe's response: the GDPR</h2>
Nevertheless, the first major piece of regulation designed counter this trend is the European Union’s General Data Protection Regulation (GDPR), which is set to go into effect on May 25th, 2018. Legal scholar Tal Z. Zarsky (2017) has written that the GDPR’s impact will be “profound…[and is] perhaps the most comprehensive and forward looking piece of legislation to address the challenges facing data protection in the digital age.”  On the other hand, the major watchdog of academic research, the Institutional Review Board, or IRB (also known as ethics committees or research ethics committees in some countries), has only undergone relatively minor cosmetic changes.


<ul>
  <li><a href="#strategies-for-dealing-with-high-cardinality-categorical-predictors">Why do we need special strategies?</a></li>
  <li><a href="#methods-explored">Methods explored</a></li>
  <li><a href="#preliminaries-a-sample-of-50000-obs-same-seed-in-all-experiments">Preliminaries</a></li>
  <li><a href="#naive-approach-no-special-processing.-base-performance">Base performance</a></li>
  <li><a href="#start-text-preprocessing-with-text2vec">Text preprocessing with text2vec</a></li>
  <li><a href="#strategy-1-naive-approach-top-50-most-common">Strategy 1: Naive Approach (Top 50 most common)</a></li>
  <li><a href="#strategy-2-impact-coding-using-the-r-package-vtreat">Strategy 2: Impact Coding using the R package vtreat</a>
    <ul>
      <li><a href="#benefits-of-impact-coding">Benefits of Impact Coding</a></li>
      <li><a href="#avoiding-nested-model-bias">Avoiding Nested model Bias</a></li>
    </ul>
  </li>
  <li><a href="#strategy-3-feature-hashing">Strategy 3: Feature Hashing</a></li>
  <li><a href="#strategy-4-string-distance-based-grouping">Strategy 4: String distance based grouping</a></li>
  <li><a href="#summary-and-conclusion">Summary and Conclusion</a></li>
</ul>

<h1 id="why-do-we-need-special-strategies-for-high-cardinality-categorical-predictors">Why do we need special strategies for high-cardinality categorical predictors?</h1>

<p>A common issue with real-word datasets is handling of categorical predictors with many unique factor levels.<sup id="fnref:1"><a href="#fn:1" class="footnote">1</a></sup> This problem is especially acute in the e-commerce, retail, and banking sectors, where predictors such as item type, zip code, or user city may wield hundreds or even thousands of unique levels. In fact, most datasets containing textual features will exhibit these issues and therefore data analysts should be well-equipped with strategies for making the most of these categorical predictors. The following list represents some of the most frequently-encountered issues when preparing such datasets for predictive modeling (taken from Mount and Zumel (2018)<sup id="fnref:2"><a href="#fn:2" class="footnote">2</a></sup>):</p>
<blockquote>
  <p>Missing (NA) or invalid categorical level values</p>
</blockquote>

<blockquote>
  <p>Novel levels encountered in model validation/testing sets</p>
</blockquote>

<blockquote>
  <p>Extremely rare or infrequent categorical levels</p>
</blockquote>

<blockquote>
  <p>Some learning methods in R, for example, can only handle categorical predictors with a maximum of 63 unique levels</p>
</blockquote>

<blockquote>
  <p>Creation of large numbers of dummy variables unnecessarily adds dimensions to the model input, slows down model training, and reduces model interpretability</p>
</blockquote>

<p>This post is an attempt to empirically evaluate several different pre-processing strategies specifically tailored to datasets containing categorical predictors with a substantial number of unique levels. Each strategy brings with it several benefits but also several drawbacks; therefore, the question of which technique is best suited for a particular dataset is left open to experimentation and will depend on the details surrounding the predictive modeling task. For example, some stakeholders may value model interpretability more than the speed at which the model can be deployed or trained. These factors will need to be taken into consideration when deciding which methods to use.</p>

<h1 id="business-impact-of-predictive-model">Business Impact of predictive model</h1>
<p>Our goal is to compare the predictive performance of four methods of dealing with datasets that include high-cardinality categorical variables. 
We don’t care so much about the absolute performance of our predictive model; rather we care about the relative improvement gained by using these various techniques.</p>

<p>To explore these strategies we’ll look at how each method performs on a sample Kickstarter dataset from Kaggle.
Can we use the textual features of the campaign title to predict the final number of campaign backers? Although this is not our main goal, we’re also interested in answering whether the text features contain any predictive signal we can use.</p>

<h4 id="why-would-we-want-to-predict-this">Why would we want to predict this?</h4>
<p>Kickstarter might want to use this information in order to advise new projects on which kinds of words tend to attract the most backers, or they could use such predictions to position some projects in visible areas on the main page in order to attract even more viewers (relying on a kind of ‘network effect’). 
Finally, by combining the estimated number of backers with an average pledge amount, Kickstarter could also generate a probability that a campaign will reach its funding goal.</p>

<p>Here’s an example of Kickstarter’s website to illustrate what we are trying to predict and where the text features come from. 
<img src="./pics/kicks.png" alt="Predictive goal" class="img-responsive" /></p>

<p>When structured, the dataset looks something like this (target variable highlighted in red):
<img src="./pics/df.png" alt="dataframe" class="img-responsive" /></p>

<h1 id="methods-explored-in-this-post">Methods explored in this post</h1>

<p>Strategy 1: <strong>Naive approach</strong>: Collapsing into top N categories</p>

<p>Strategy 2: <strong>Impact coding</strong></p>

<p>Strategy 3: <strong>String distance</strong> and <strong>clustering</strong></p>

<p>Strategy 4: <strong>Feature hashing</strong></p>

<h1 id="preliminaries">Preliminaries</h1>

<p>In order to make our comparison of strategies as fair as possible, we will need to set up some base conditions when comparing the different approaches. 
The final dimensions of the training sets used during model estimation will differ, however, depending on the technique used. 
For example, in our feature hashed version, we will have over 500,000 predictors. All trained models will have the following in common:</p>

<ul>
  <li>Use 500 text features (based on the 500 most frequent words in the training set)</li>
  <li>Same seed numbers</li>
  <li>Tf-idf weights for the text features based on the training set</li>
  <li>80/20 train-test split</li>
  <li>5 fold cross validation used whenever possible to tune hyperparameters; otherwise set to default</li>
  <li>Glmnet and xgboost models will be trained</li>
  <li>Test set RMSE is evaluation metric</li>
</ul>

<h1 id="load-dependencies-and-examine-data">Load dependencies and examine data</h1>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">caret</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">xgboost</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">tidyverse</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">stringdist</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">ModelMetrics</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">text2vec</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">xray</span><span class="p">)</span><span class="w">

</span><span class="n">df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">read.csv</span><span class="p">(</span><span class="s1">'kick_sample.csv'</span><span class="p">,</span><span class="w"> </span><span class="n">stringsAsFactors</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">F</span><span class="p">)</span><span class="w">
</span><span class="n">glimpse</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## Observations: 50,000
## Variables: 15
## $ name          &lt;chr&gt; "3 great ways to have a big income with no  form...
## $ category      &lt;chr&gt; "Academic", "Music", "Animals", "Photography", "...
## $ main_category &lt;chr&gt; "Publishing", "Music", "Photography", "Photograp...
## $ currency      &lt;chr&gt; "USD", "GBP", "USD", "USD", "EUR", "USD", "USD",...
## $ backers       &lt;int&gt; 0, 51, 136, 0, 3, 30, 0, 6, 232, 2, 170, 104, 1,...
## $ country       &lt;chr&gt; "US", "GB", "US", "US", "DE", "US", "US", "US", ...
## $ goal          &lt;dbl&gt; 5000.00, 7855.97, 2200.00, 5000.00, 29296.76, 20...
## $ dow_deadline  &lt;chr&gt; "Sun", "Wed", "Sun", "Fri", "Sun", "Sat", "Mon",...
## $ yr_deadline   &lt;int&gt; 2015, 2017, 2014, 2014, 2016, 2012, 2017, 2017, ...
## $ mo_deadline   &lt;int&gt; 7, 10, 11, 8, 9, 6, 4, 6, 5, 9, 11, 10, 7, 3, 10...
## $ word_count    &lt;int&gt; 11, 1, 2, 6, 7, 7, 3, 5, 10, 8, 8, 5, 10, 1, 6, ...
## $ ave_sentiment &lt;dbl&gt; 0.22613350, 0.00000000, 0.00000000, 0.00000000, ...
## $ total_chars   &lt;int&gt; 59, 8, 22, 28, 40, 57, 31, 31, 57, 49, 44, 33, 6...
## $ exc_count     &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...
## $ extreme       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...
</code></pre></div></div>

<p>This dataset is typical for one you might see on Kaggle or obtain from webscraping. There are tons of categories. What should we do?</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">xray</span><span class="o">::</span><span class="n">anomalies</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="w">
</span><span class="n">x</span><span class="o">$</span><span class="n">variables</span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">filter</span><span class="p">(</span><span class="n">type</span><span class="o">==</span><span class="w"> </span><span class="s1">'Character'</span><span class="p">)</span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">select</span><span class="p">(</span><span class="n">Variable</span><span class="p">,</span><span class="w"> </span><span class="n">qDistinct</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>##        Variable qDistinct
## 1  dow_deadline         7
## 2      currency        14
## 3 main_category        15
## 4       country        23
## 5      category       159
## 6          name     49943
</code></pre></div></div>

<p>There are over 159 unique levels in the “category” column alone.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">num_v</span><span class="w"> </span><span class="o">&lt;-</span><span class="n">x</span><span class="o">$</span><span class="n">variables</span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">filter</span><span class="p">(</span><span class="n">type</span><span class="o">==</span><span class="w"> </span><span class="s1">'Character'</span><span class="p">)</span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">select</span><span class="p">(</span><span class="n">Variable</span><span class="p">,</span><span class="w"> </span><span class="n">qDistinct</span><span class="p">)</span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">filter</span><span class="p">(</span><span class="n">Variable</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="s1">'name'</span><span class="p">)</span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">pull</span><span class="p">(</span><span class="n">qDistinct</span><span class="p">)</span><span class="o">%&gt;%</span><span class="w">
  </span><span class="nf">sum</span><span class="p">()</span><span class="w">

</span><span class="n">cat</span><span class="p">(</span><span class="s1">'There are'</span><span class="p">,</span><span class="w"> </span><span class="n">num_v</span><span class="p">,</span><span class="w"> </span><span class="s1">'unique factor levels not including the unique campaign names'</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## There are 218 unique factor levels not including the unique campaign names
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#plot counts of factor levels for category</span><span class="w">
</span><span class="n">df</span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">count</span><span class="p">(</span><span class="n">category</span><span class="p">,</span><span class="w"> </span><span class="n">sort</span><span class="o">=</span><span class="nb">T</span><span class="p">)</span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">ggplot</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">reorder</span><span class="p">(</span><span class="n">category</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">),</span><span class="n">n</span><span class="p">))</span><span class="o">+</span><span class="w">
  </span><span class="n">geom_col</span><span class="p">()</span><span class="o">+</span><span class="w">
  </span><span class="n">coord_flip</span><span class="p">()</span><span class="o">+</span><span class="w">
  </span><span class="n">theme_minimal</span><span class="p">()</span><span class="o">+</span><span class="w">
  </span><span class="n">theme</span><span class="p">(</span><span class="n">axis.text.y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">element_text</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="m">2</span><span class="p">))</span><span class="o">+</span><span class="w">
  </span><span class="n">labs</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">'Unique categories'</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="o">=</span><span class="s1">'Times appears in dataset'</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p><img src="finalreport_files/figure-markdown_github/unnamed-chunk-2-1.png" alt="" /></p>

<p>What is the minimum number of unique levels needed to account for roughly 80% of all observed levels?
Generally, we’ll find that this tends to follow Pareto’s 80/20 law. In this case we find it’s more like 80/31.
In other words, 31% of unique category levels account for 80% of all observed categories.</p>
<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">dplyr</span><span class="o">::</span><span class="n">count</span><span class="p">(</span><span class="n">category</span><span class="p">,</span><span class="w"> </span><span class="n">sort</span><span class="o">=</span><span class="nb">T</span><span class="p">)</span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">mutate</span><span class="p">(</span><span class="n">total</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="n">n</span><span class="p">),</span><span class="w">
         </span><span class="n">perc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n</span><span class="o">/</span><span class="n">total</span><span class="p">,</span><span class="w">
         </span><span class="n">cum_perc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">cumsum</span><span class="p">(</span><span class="n">perc</span><span class="p">),</span><span class="w">
         </span><span class="n">nums</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="n">n_distinct</span><span class="p">(</span><span class="n">category</span><span class="p">))</span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">ggplot</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">cum_perc</span><span class="p">,</span><span class="w"> </span><span class="n">nums</span><span class="p">))</span><span class="o">+</span><span class="w">
  </span><span class="n">geom_line</span><span class="p">()</span><span class="o">+</span><span class="w">
  </span><span class="n">geom_vline</span><span class="p">(</span><span class="n">xintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">.80</span><span class="p">,</span><span class="w"> </span><span class="n">linetype</span><span class="o">=</span><span class="s1">'dashed'</span><span class="p">)</span><span class="o">+</span><span class="w">
  </span><span class="n">labs</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">'Cumulative Percentage'</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="s1">'Number of unique factor levels'</span><span class="p">,</span><span class="w"> </span><span class="n">title</span><span class="o">=</span><span class="s1">'How many unique levels capture 80% of all observed levels?'</span><span class="p">)</span><span class="o">+</span><span class="w">
  </span><span class="n">theme_minimal</span><span class="p">()</span><span class="w">
</span></code></pre></div></div>

<p><img src="finalreport_files/figure-markdown_github/unnamed-chunk-2-2.png" alt="" /></p>

<h1 id="visualizing-the-outcome-distribution">Visualizing the outcome distribution</h1>

<p>Before we get into the pre-processing, let’s quickly look at the distribution of the target variable.</p>

<p>We see a highly skewed outcome variable with lots of campaigns getting 0 or nearly 0 backers, but some getting up to nearly 92,000 followers. This may explain why regression techniques do not seem to perform well on this dataset.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">theme_set</span><span class="p">(</span><span class="n">theme_minimal</span><span class="p">())</span><span class="w">
</span><span class="n">ggplot</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="w"> </span><span class="n">aes</span><span class="p">(</span><span class="n">backers</span><span class="p">))</span><span class="o">+</span><span class="w">
  </span><span class="n">geom_histogram</span><span class="p">()</span><span class="o">+</span><span class="w">
  </span><span class="n">scale_x_log10</span><span class="p">()</span><span class="w">
</span></code></pre></div></div>

<p><img src="finalreport_files/figure-markdown_github/unnamed-chunk-3-1.png" alt="" /></p>

<p>The existence of so many viral outlier campaigns makes it hard to even visualize. So let’s focus just on the more successful campaigns that attracted more than 5000 backers.
We can see some campaigns managed to get over 25,000 backers, but the vast majority are near 0.</p>
<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">filter</span><span class="p">(</span><span class="n">backers</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="m">5000</span><span class="p">)</span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">ggplot</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">backers</span><span class="p">))</span><span class="o">+</span><span class="w">
  </span><span class="n">geom_histogram</span><span class="p">()</span><span class="w">
</span></code></pre></div></div>

<p><img src="finalreport_files/figure-markdown_github/unnamed-chunk-3-2.png" alt="" /></p>

<p>Let’s look at more summary stats of the outcome variable. We can see a huge discrepancy between the mean and median values and so it’s not surprising the skew is large.
The very large kurtosis statistic tells us about the presence of outliers in the tails of our distribution. Clearly this outcome variable is not following a normal distribution.
Without any transformations of the outcome variable, we can already imagine that regression-based approaches may have some problems.</p>
<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">psych</span><span class="p">)</span><span class="w">
</span><span class="n">psych</span><span class="o">::</span><span class="n">describe</span><span class="p">(</span><span class="n">df</span><span class="o">%&gt;%</span><span class="n">select</span><span class="p">(</span><span class="n">backers</span><span class="p">,</span><span class="w"> </span><span class="n">goal</span><span class="p">))</span><span class="w">
</span></code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>##         vars     n     mean         sd  median trimmed     mad  min
## backers    1 50000   105.68     907.92   12.00   28.72   17.79 0.00
## goal       2 50000 41446.59 1020747.46 5375.01 9366.08 6747.69 0.15
##               max     range  skew kurtosis      se
## backers     91585     91585 59.93  4957.11    4.06
## goal    100000000 100000000 80.53  7174.86 4564.92
</code></pre></div></div>

<h1 id="base-performance-no-special-processing">Base performance: No special processing</h1>

<p>What kind of results do you get if you simply try to make a basic model using tf-idf weights for the features? Before evaluating the performance impact of the other methods, a “control” condition of no special pre-processing was made in order to provide a benchmark.</p>

<p>Note here we need to make sure we are splitting the data in the same way for each technique. We will keep 80% of the observations to train our models and compare performance on the remaining 20%.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w"> </span><span class="c1">#BREAKUP INTO TRAINING AND TESTING</span><span class="w">
</span><span class="n">set.seed</span><span class="p">(</span><span class="m">1</span><span class="p">)</span><span class="w">
</span><span class="n">sp</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">createDataPartition</span><span class="p">(</span><span class="n">df</span><span class="o">$</span><span class="n">backers</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="o">=</span><span class="m">.8</span><span class="p">,</span><span class="w"> </span><span class="n">list</span><span class="o">=</span><span class="kc">FALSE</span><span class="p">)</span><span class="w">
</span><span class="n">train</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">df</span><span class="p">[</span><span class="n">sp</span><span class="p">,]</span><span class="w">
</span><span class="n">test</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">df</span><span class="p">[</span><span class="o">-</span><span class="n">sp</span><span class="p">,]</span><span class="w">
</span></code></pre></div></div>

<p>Just to verify the splitting procedure, let’s visualize the two outcome distributions in training and testing sets. They appear roughly the same. This is because, by default, caret uses a stratified sampling procedure to create training and testing sets.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">f</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">bind_rows</span><span class="p">(</span><span class="n">train</span><span class="p">,</span><span class="w"> </span><span class="n">test</span><span class="p">,</span><span class="w"> </span><span class="n">.id</span><span class="o">=</span><span class="s1">'set'</span><span class="p">)</span><span class="w">
</span><span class="n">ggplot</span><span class="p">(</span><span class="n">f</span><span class="p">,</span><span class="n">aes</span><span class="p">(</span><span class="n">backers</span><span class="p">,</span><span class="w"> </span><span class="n">fill</span><span class="o">=</span><span class="n">set</span><span class="p">))</span><span class="o">+</span><span class="w">
  </span><span class="n">geom_histogram</span><span class="p">(</span><span class="n">binwidth</span><span class="o">=</span><span class="m">100</span><span class="p">)</span><span class="o">+</span><span class="w">
  </span><span class="n">coord_cartesian</span><span class="p">(</span><span class="n">xlim</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="m">2000</span><span class="p">))</span><span class="o">+</span><span class="w">
  </span><span class="n">facet_wrap</span><span class="p">(</span><span class="o">~</span><span class="n">set</span><span class="p">)</span><span class="o">+</span><span class="w">
  </span><span class="n">theme_minimal</span><span class="p">()</span><span class="w">
</span></code></pre></div></div>

<p><img src="finalreport_files/figure-markdown_github/unnamed-chunk-5-1.png" alt="" /></p>

<h1 id="start-text-preprocessing-with-text2vec">Start text preprocessing with text2vec</h1>

<p>One key issue here is to make sure you are not mixing information from your test set into your training set (i.e., information leakage). In order to prevent this we need to apply separate TF-IDF weights for train and test sets. Often times in Kaggle you will see people apply tf-idf weighting to the full dataset and then afterwards split back into training and testing. If done this way, your performance estimates will likely be overly optimistic on new data.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">prep_fun</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
  </span><span class="n">x</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> 
    </span><span class="c1"># make text lower case</span><span class="w">
    </span><span class="n">str_to_lower</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> 
    </span><span class="c1"># remove non-alphanumeric symbols</span><span class="w">
    </span><span class="n">str_replace_all</span><span class="p">(</span><span class="s2">"[^[:alpha:]]"</span><span class="p">,</span><span class="w"> </span><span class="s2">" "</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> 
    </span><span class="c1"># collapse multiple spaces</span><span class="w">
    </span><span class="n">str_replace_all</span><span class="p">(</span><span class="s2">"\\s+"</span><span class="p">,</span><span class="w"> </span><span class="s2">" "</span><span class="p">)</span><span class="w">
</span><span class="p">}</span><span class="w">
</span><span class="c1">#prep_fun = tolower</span><span class="w">
</span><span class="n">tok_fun</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">word_tokenizer</span><span class="w">

</span><span class="c1">#try to fix foreign characters</span><span class="w">
</span><span class="n">df</span><span class="o">$</span><span class="n">name</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">iconv</span><span class="p">(</span><span class="n">df</span><span class="o">$</span><span class="n">name</span><span class="p">,</span><span class="w"> </span><span class="s1">'Latin-9'</span><span class="p">)</span><span class="w">

</span><span class="c1">#create training iterator</span><span class="w">
</span><span class="n">it_train</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">itoken</span><span class="p">(</span><span class="n">train</span><span class="o">$</span><span class="n">name</span><span class="p">,</span><span class="w"> 
                  </span><span class="n">preprocessor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prep_fun</span><span class="p">,</span><span class="w"> 
                  </span><span class="n">tokenizer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tok_fun</span><span class="p">,</span><span class="w"> 
                  </span><span class="n">progressbar</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w">
</span><span class="n">stop_words</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="n">tm</span><span class="o">::</span><span class="n">stopwords</span><span class="p">(</span><span class="s1">'en'</span><span class="p">),</span><span class="s2">"i"</span><span class="p">,</span><span class="w"> </span><span class="s2">"me"</span><span class="p">,</span><span class="w"> </span><span class="s2">"my"</span><span class="p">,</span><span class="w"> </span><span class="s2">"myself"</span><span class="p">,</span><span class="w"> 
               </span><span class="s2">"we"</span><span class="p">,</span><span class="w"> </span><span class="s2">"our"</span><span class="p">,</span><span class="w"> </span><span class="s2">"ours"</span><span class="p">,</span><span class="w"> </span><span class="s2">"ourselves"</span><span class="p">,</span><span class="w"> </span><span class="s2">"you"</span><span class="p">,</span><span class="w"> </span><span class="s2">"your"</span><span class="p">,</span><span class="w"> </span><span class="s2">"yours"</span><span class="p">,</span><span class="w">
               </span><span class="s1">'a'</span><span class="p">,</span><span class="w"> </span><span class="s1">'the'</span><span class="p">,</span><span class="w"> </span><span class="s1">'for'</span><span class="p">,</span><span class="w"> </span><span class="s1">'of'</span><span class="p">,</span><span class="w"> </span><span class="s1">'and'</span><span class="p">,</span><span class="w"> </span><span class="s1">'in'</span><span class="p">,</span><span class="w"> </span><span class="s1">'to'</span><span class="p">,</span><span class="w"> </span><span class="s1">'act'</span><span class="p">,</span><span class="w"> </span><span class="s1">'s'</span><span class="p">)</span><span class="w">

</span><span class="c1">#we'll use up to trigrams here</span><span class="w">
</span><span class="n">vocab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">create_vocabulary</span><span class="p">(</span><span class="n">it_train</span><span class="p">,</span><span class="w"> </span><span class="n">ngram</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">),</span><span class="w"> </span><span class="n">stopwords</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">stop_words</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#we keep 500 words max. this is already pushing memory limits of R</span><span class="w">
</span><span class="c1">#if you want to use dataframes as your data type</span><span class="w">
</span><span class="n">pruned_vocab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prune_vocabulary</span><span class="p">(</span><span class="n">vocab</span><span class="p">,</span><span class="w"> 
                                </span><span class="n">term_count_min</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">10</span><span class="p">,</span><span class="w">
                                </span><span class="n">vocab_term_max</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">500</span><span class="p">)</span><span class="w"> 

</span><span class="c1">#keep &lt;- which(nchar(pruned_vocab$term) &gt; 1)</span><span class="w">
</span><span class="c1">#pruned_vocab &lt;- pruned_vocab[keep,]</span><span class="w">
</span><span class="n">vectorizer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">vocab_vectorizer</span><span class="p">(</span><span class="n">pruned_vocab</span><span class="p">)</span><span class="w">

</span><span class="c1">#create training dtm</span><span class="w">
</span><span class="n">dtm_train</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="n">create_dtm</span><span class="p">(</span><span class="n">it_train</span><span class="p">,</span><span class="w"> </span><span class="n">vectorizer</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p>Here’s what our text features will look like. Notice the foreign characters that weren’t quite converted right. They may act as indicators of foreign Kickstarter campaigns, which may prove useful when making predictions.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">head</span><span class="p">(</span><span class="n">pruned_vocab</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## Number of docs: 40001 
## 194 stopwords: i, me, my, myself, we, our ... 
## ngram_min = 1; ngram_max = 3 
## Vocabulary: 
##      term term_count doc_count
## 1:    new       1510      1490
## 2:  album       1442      1439
## 3:      u       1350      1108
## 4:   fffd       1269      1028
## 5: u_fffd       1269      1028
## 6:   film       1251      1241
</code></pre></div></div>

<p>We do the same thing with the test set, but at the end we apply the fit_transform object built from the training set onto the test set. This safeguards against information leakage. If we were lazy or wanted to do slightly better in a Kaggle contest, we wouldn’t need this step–we would just use the same tf-idf weightings for both train and test.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Now rinse and repeat for the test set</span><span class="w">
</span><span class="n">it_test</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">itoken</span><span class="p">(</span><span class="n">test</span><span class="o">$</span><span class="n">name</span><span class="p">,</span><span class="w"> 
                  </span><span class="n">preprocessor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prep_fun</span><span class="p">,</span><span class="w"> 
                  </span><span class="n">tokenizer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tok_fun</span><span class="p">,</span><span class="w"> 
                  </span><span class="n">progressbar</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w">
</span><span class="n">stop_words</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="n">tm</span><span class="o">::</span><span class="n">stopwords</span><span class="p">(</span><span class="s1">'en'</span><span class="p">),</span><span class="s2">"i"</span><span class="p">,</span><span class="w"> </span><span class="s2">"me"</span><span class="p">,</span><span class="w"> </span><span class="s2">"my"</span><span class="p">,</span><span class="w"> </span><span class="s2">"myself"</span><span class="p">,</span><span class="w"> 
               </span><span class="s2">"we"</span><span class="p">,</span><span class="w"> </span><span class="s2">"our"</span><span class="p">,</span><span class="w"> </span><span class="s2">"ours"</span><span class="p">,</span><span class="w"> </span><span class="s2">"ourselves"</span><span class="p">,</span><span class="w"> </span><span class="s2">"you"</span><span class="p">,</span><span class="w"> </span><span class="s2">"your"</span><span class="p">,</span><span class="w"> </span><span class="s2">"yours"</span><span class="p">,</span><span class="w">
               </span><span class="s1">'a'</span><span class="p">,</span><span class="w"> </span><span class="s1">'the'</span><span class="p">,</span><span class="w"> </span><span class="s1">'for'</span><span class="p">,</span><span class="w"> </span><span class="s1">'of'</span><span class="p">,</span><span class="w"> </span><span class="s1">'and'</span><span class="p">,</span><span class="w"> </span><span class="s1">'in'</span><span class="p">,</span><span class="w"> </span><span class="s1">'to'</span><span class="p">,</span><span class="w"> </span><span class="s1">'act'</span><span class="p">,</span><span class="w"> </span><span class="s1">'s'</span><span class="p">)</span><span class="w">

</span><span class="n">vocab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">create_vocabulary</span><span class="p">(</span><span class="n">it_test</span><span class="p">,</span><span class="w"> </span><span class="n">ngram</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">),</span><span class="w"> </span><span class="n">stopwords</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">stop_words</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#do dtm for test set</span><span class="w">
</span><span class="n">dtm_test</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">create_dtm</span><span class="p">(</span><span class="n">it_test</span><span class="p">,</span><span class="w"> </span><span class="n">vectorizer</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#should be same number of columns</span><span class="w">
</span><span class="nf">dim</span><span class="p">(</span><span class="n">dtm_test</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 9999  500
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">dim</span><span class="p">(</span><span class="n">dtm_train</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 40001   500
</code></pre></div></div>

<p>So we see both the training and test sets have 500 text features.</p>

<p>Now we calculate the tf-idf scores for the training set (fit_transform) and then transform() the test set.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#create tf idf instance. apply to train then transform test based on it</span><span class="w">
</span><span class="n">model_tfidf</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">TfIdf</span><span class="o">$</span><span class="n">new</span><span class="p">()</span><span class="w">

</span><span class="c1">#fit tfidf based on train</span><span class="w">
</span><span class="n">dtm_tfidf_train</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model_tfidf</span><span class="o">$</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">dtm_train</span><span class="p">)</span><span class="w">

</span><span class="c1">#use train tfidf to transform test</span><span class="w">
</span><span class="n">dtm_tfidf_test</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model_tfidf</span><span class="o">$</span><span class="n">transform</span><span class="p">(</span><span class="n">dtm_test</span><span class="p">)</span><span class="w">

</span><span class="n">dtm_full</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">as.data.frame</span><span class="p">(</span><span class="n">as.matrix</span><span class="p">(</span><span class="n">dtm_tfidf_train</span><span class="p">),</span><span class="w"> </span><span class="n">stringsAsFactors</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">F</span><span class="p">)</span><span class="w">
</span><span class="n">dtm_full_test</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">as.data.frame</span><span class="p">(</span><span class="n">as.matrix</span><span class="p">(</span><span class="n">dtm_tfidf_test</span><span class="p">),</span><span class="w"> </span><span class="n">stringsAsFactors</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">F</span><span class="p">)</span><span class="w">

</span><span class="nf">dim</span><span class="p">(</span><span class="n">dtm_full</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 40001   500
</code></pre></div></div>

<p>So we coerce back to a dataframe for later manipulation and visualization. Plus if you’re an average R user, you probably are used to thinking in terms of dataframes (and not sparse matrices).</p>

<p>We do some final cleaning up and add back the other predictors.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#now get rid of "name" column before dividing back into train test</span><span class="w">
</span><span class="c1">#we've already turned this column into text features</span><span class="w">
</span><span class="n">train_inp</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">train</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">select</span><span class="p">(</span><span class="o">-</span><span class="n">name</span><span class="p">)</span><span class="w">
</span><span class="n">test_inp</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">test</span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">select</span><span class="p">(</span><span class="o">-</span><span class="n">name</span><span class="p">)</span><span class="w">

</span><span class="c1">#COMBINE BACK WITH ORIGINAL FEATURES. now 515 features</span><span class="w">
</span><span class="n">full_train</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">cbind</span><span class="p">(</span><span class="n">dtm_full</span><span class="p">,</span><span class="w"> </span><span class="n">train_inp</span><span class="p">)</span><span class="w">
</span><span class="n">full_test</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">cbind</span><span class="p">(</span><span class="n">dtm_full_test</span><span class="p">,</span><span class="w"> </span><span class="n">test_inp</span><span class="p">)</span><span class="w">

</span><span class="c1">#word is same as column name. need make unique! common error</span><span class="w">
</span><span class="n">colnames</span><span class="p">(</span><span class="n">full_train</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">make.unique</span><span class="p">(</span><span class="n">colnames</span><span class="p">(</span><span class="n">full_train</span><span class="p">))</span><span class="w">
</span><span class="n">colnames</span><span class="p">(</span><span class="n">full_test</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">make.unique</span><span class="p">(</span><span class="n">colnames</span><span class="p">(</span><span class="n">full_test</span><span class="p">))</span><span class="w">

</span><span class="c1">#housekeeping to free up RAM</span><span class="w">
</span><span class="n">rm</span><span class="p">(</span><span class="n">dtm_full</span><span class="p">)</span><span class="w">
</span><span class="n">rm</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span><span class="w">
</span><span class="n">rm</span><span class="p">(</span><span class="n">dtm_test</span><span class="p">)</span><span class="w">
</span><span class="n">rm</span><span class="p">(</span><span class="n">dtm_tfidf_test</span><span class="p">)</span><span class="w">
</span><span class="n">rm</span><span class="p">(</span><span class="n">dtm_tfidf_train</span><span class="p">)</span><span class="w">
</span><span class="n">rm</span><span class="p">(</span><span class="n">dtm_train</span><span class="p">)</span><span class="w">
</span><span class="n">rm</span><span class="p">(</span><span class="n">dtm_full_test</span><span class="p">)</span><span class="w">
</span><span class="n">gc</span><span class="p">()</span><span class="w">
</span></code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>##            used  (Mb) gc trigger  (Mb) max used  (Mb)
## Ncells  2841776 151.8    5613254 299.8  4335588 231.6
## Vcells 32269311 246.2   61639038 470.3 61638884 470.3
</code></pre></div></div>

<h1 id="set-up-our-cross-validation-scheme">Set up our cross validation scheme</h1>

<p>Here we use adaptive resampling with a random search to find the best hyperparameter values. Essentially adaptive resampling looks to infer which hyperparameters are clearly not optimal and then does not continue sampling values near those sub-optimal values. The benefit to such a procedure is that it can reduce training/tuning time since we only focus on hyperparameter values that are likely to lead to better performance. As the cross validation proceeds, we can eliminate testing certain values of hyperparameters.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#SET UP FOLDS WITHIN TRAINING SET</span><span class="w">
</span><span class="n">set.seed</span><span class="p">(</span><span class="m">123</span><span class="p">)</span><span class="w">
</span><span class="n">myFolds</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">createFolds</span><span class="p">(</span><span class="n">full_train</span><span class="o">$</span><span class="n">backers</span><span class="p">,</span><span class="w"> </span><span class="n">k</span><span class="o">=</span><span class="m">5</span><span class="p">)</span><span class="w">

</span><span class="c1"># Create reusable trainControl object: myControl</span><span class="w">
</span><span class="n">control</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">trainControl</span><span class="p">(</span><span class="w">
  </span><span class="n">method</span><span class="o">=</span><span class="s1">'adaptive_cv'</span><span class="p">,</span><span class="w"> </span><span class="n">number</span><span class="o">=</span><span class="m">5</span><span class="p">,</span><span class="w">
  </span><span class="n">verboseIter</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,</span><span class="w">
  </span><span class="n">index</span><span class="o">=</span><span class="n">myFolds</span><span class="p">,</span><span class="w">
  </span><span class="n">preProcOptions</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"nzv"</span><span class="p">,</span><span class="w"> </span><span class="s2">"center"</span><span class="p">,</span><span class="w"> </span><span class="s2">"scale"</span><span class="p">,</span><span class="w"> </span><span class="s2">"pca"</span><span class="p">),</span><span class="w">
  </span><span class="n">returnData</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">,</span><span class="w">
   </span><span class="n">adaptive</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">min</span><span class="o">=</span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="m">0.05</span><span class="p">,</span><span class="w"> </span><span class="n">method</span><span class="o">=</span><span class="s1">'gls'</span><span class="p">,</span><span class="w"> </span><span class="n">complete</span><span class="o">=</span><span class="kc">FALSE</span><span class="p">,</span><span class="w"> </span><span class="n">search</span><span class="o">=</span><span class="s1">'random'</span><span class="p">)</span><span class="w">
  </span><span class="c1">#savePredictions = 'final'</span><span class="w">
</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<h1 id="start-training-models-elastic-net-and-xgboost">Start training models: elastic net and xgboost</h1>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">set.seed</span><span class="p">(</span><span class="m">1</span><span class="p">)</span><span class="w">
</span><span class="n">glm_model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">train</span><span class="p">(</span><span class="n">backers</span><span class="w"> </span><span class="o">~</span><span class="n">.</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="o">=</span><span class="w"> </span><span class="n">full_train</span><span class="p">,</span><span class="w"> </span><span class="n">method</span><span class="o">=</span><span class="s1">'glmnet'</span><span class="p">,</span><span class="w"> </span><span class="n">metric</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"RMSE"</span><span class="p">,</span><span class="w"> </span><span class="n">trControl</span><span class="o">=</span><span class="n">control</span><span class="p">)</span><span class="w">

</span><span class="n">set.seed</span><span class="p">(</span><span class="m">1</span><span class="p">)</span><span class="w">
</span><span class="n">xg_model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">train</span><span class="p">(</span><span class="n">backers</span><span class="w"> </span><span class="o">~</span><span class="n">.</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="o">=</span><span class="w"> </span><span class="n">full_train</span><span class="p">,</span><span class="w"> </span><span class="n">method</span><span class="o">=</span><span class="s1">'xgbTree'</span><span class="p">,</span><span class="w"> </span><span class="n">metric</span><span class="o">=</span><span class="s1">'RMSE'</span><span class="p">,</span><span class="w">
                  </span><span class="n">trControl</span><span class="o">=</span><span class="n">control</span><span class="p">,</span><span class="w"> </span><span class="n">tuneLength</span><span class="o">=</span><span class="m">2</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<h1 id="examine-model-performance">Examine model performance</h1>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#For GLMNET</span><span class="w">
</span><span class="n">resampleHist</span><span class="p">(</span><span class="n">glm_model</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p><img src="finalreport_files/figure-markdown_github/unnamed-chunk-13-1.png" alt="" /></p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plot</span><span class="p">(</span><span class="n">glm_model</span><span class="p">,</span><span class="w"> </span><span class="n">plotType</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">'level'</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p><img src="finalreport_files/figure-markdown_github/unnamed-chunk-13-2.png" alt="" /></p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">varImp</span><span class="p">(</span><span class="n">glm_model</span><span class="p">,</span><span class="w"> </span><span class="n">scale</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## glmnet variable importance
## 
##   only 20 most important variables shown (out of 721)
## 
##                          Overall
## categoryGaming Hardware 100.0000
## video_game               40.4549
## world_first              34.1945
## categoryTabletop Games   22.5124
## android                  15.1998
## categoryProduct Design   11.5854
## categoryHardware         10.5196
## categoryVideo Games       7.9148
## main_categoryGames        6.9413
## categoryWearables         5.4757
## kind                      4.1382
## smart                     3.9445
## pocket                    3.4700
## main_categoryDesign       2.3441
## country.1US               1.7842
## light                     1.4402
## pc                        1.1729
## world                     0.9437
## main_categoryTechnology   0.8501
## categoryGadgets           0.7044
</code></pre></div></div>

<p>Here we see that category columns do seem to be important to predictions, at least as judged by the absolute value of the estimated coefficient.
These values are scaled so that categoryGamingHardware has the biggest absolute valued coefficient of all predictors in the final model. Some text such as “video_game” and ‘world_first’ also appear to be useful as predictors.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#mean RMSE of 5 folds?</span><span class="w">
</span><span class="n">mean</span><span class="p">(</span><span class="n">glm_model</span><span class="o">$</span><span class="n">resample</span><span class="o">$</span><span class="n">RMSE</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 733.5763
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#FOR XGBOOST</span><span class="w">
</span><span class="n">resampleHist</span><span class="p">(</span><span class="n">xg_model</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p><img src="finalreport_files/figure-markdown_github/unnamed-chunk-13-3.png" alt="" /></p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plot</span><span class="p">(</span><span class="n">xg_model</span><span class="p">,</span><span class="w"> </span><span class="n">plotType</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">'level'</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p><img src="finalreport_files/figure-markdown_github/unnamed-chunk-13-4.png" alt="" /><img src="finalreport_files/figure-markdown_github/unnamed-chunk-13-5.png" alt="" /></p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">varImp</span><span class="p">(</span><span class="n">xg_model</span><span class="p">,</span><span class="w"> </span><span class="n">scale</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## xgbTree variable importance
## 
##   only 20 most important variables shown (out of 721)
## 
##                         Overall
## goal                    100.000
## kind                     95.546
## main_categoryGames       39.757
## video_game               36.597
## categoryTabletop Games   34.201
## world_first              28.512
## android                  25.003
## categoryGaming Hardware  21.571
## main_categoryDesign      10.726
## categoryProduct Design   10.267
## smart                     4.551
## pocket                    3.646
## total_chars               0.000
## day                       0.000
## categoryDance             0.000
## re                        0.000
## categoryMobile Games      0.000
## community                 0.000
## country.1HK               0.000
## wars                      0.000
</code></pre></div></div>

<p>This ranking of importance backs up what the glmnet model was telling us: category information and text features are indeed useful in making predictions. It is interesting that the campaign’s goal amount is deemed the most important predictor.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#mean RMSE for the 5 folds?</span><span class="w">
</span><span class="n">mean</span><span class="p">(</span><span class="n">xg_model</span><span class="o">$</span><span class="n">resample</span><span class="o">$</span><span class="n">RMSE</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 739.2199
</code></pre></div></div>

<p>It’s worth pointing out that if we relied simply on the in-fold RMSE to judge predictive performance, we would be expecting an out of sample RMSE around 740. It turns out that due to the presence of viral campaigns in the test set that this estimate is not quite reflective of the variety of data one might encounter once the predictive model were deployed on new campaigns.
This is one argument why we want to keep a completely independent test set to mimic the performance in a deployed setting. We’ll do that below.</p>

<h1 id="examine-the-predictions">Examine the predictions</h1>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">Metrics</span><span class="p">)</span><span class="w">
</span><span class="c1">#GET PREDICTIONS</span><span class="w">
</span><span class="n">prd</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">data.frame</span><span class="p">(</span><span class="n">predictions_glm</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">predict</span><span class="p">(</span><span class="n">glm_model</span><span class="p">,</span><span class="w"> </span><span class="n">full_test</span><span class="p">),</span><span class="w">
                  </span><span class="n">predictions_xg</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">predict</span><span class="p">(</span><span class="n">xg_model</span><span class="p">,</span><span class="w"> </span><span class="n">full_test</span><span class="p">),</span><span class="w">
                  </span><span class="n">actuals</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">full_test</span><span class="o">$</span><span class="n">backers</span><span class="p">)</span><span class="w">

</span><span class="c1">#calculate rmse GLMNET</span><span class="w">
</span><span class="n">rmse</span><span class="p">(</span><span class="n">prd</span><span class="o">$</span><span class="n">actuals</span><span class="p">,</span><span class="w"> </span><span class="n">prd</span><span class="o">$</span><span class="n">predictions_glm</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 1416.292
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#calculate rmse xgboost</span><span class="w">
</span><span class="n">rmse</span><span class="p">(</span><span class="n">prd</span><span class="o">$</span><span class="n">actuals</span><span class="p">,</span><span class="w"> </span><span class="n">prd</span><span class="o">$</span><span class="n">predictions_xg</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 1413.289
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#check against training mean</span><span class="w">
</span><span class="n">rmse</span><span class="p">(</span><span class="n">prd</span><span class="o">$</span><span class="n">actuals</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">full_train</span><span class="o">$</span><span class="n">backers</span><span class="p">))</span><span class="w">
</span></code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 1419.206
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#plot both on top </span><span class="w">
</span><span class="n">prd</span><span class="o">%&gt;%</span><span class="w">
</span><span class="n">ggplot</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">actuals</span><span class="p">,</span><span class="w"> </span><span class="n">predictions_glm</span><span class="p">))</span><span class="o">+</span><span class="w">
  </span><span class="n">geom_point</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="m">.2</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">)</span><span class="o">+</span><span class="w">
  </span><span class="n">geom_point</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">actuals</span><span class="p">,</span><span class="w"> </span><span class="n">predictions_xg</span><span class="p">),</span><span class="n">size</span><span class="o">=</span><span class="m">1</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="m">.2</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">)</span><span class="o">+</span><span class="w">
  </span><span class="n">geom_abline</span><span class="p">(</span><span class="n">slope</span><span class="o">=</span><span class="m">1</span><span class="p">)</span><span class="o">+</span><span class="w">
  </span><span class="n">scale_x_log10</span><span class="p">()</span><span class="o">+</span><span class="w">
  </span><span class="n">scale_y_log10</span><span class="p">()</span><span class="o">+</span><span class="w">
  </span><span class="n">theme_minimal</span><span class="p">()</span><span class="w">
</span></code></pre></div></div>

<p><img src="finalreport_files/figure-markdown_github/unnamed-chunk-14-1.png" alt="" /></p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#density plot</span><span class="w">
</span><span class="n">prd</span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">gather</span><span class="p">()</span><span class="o">%&gt;%</span><span class="w">
</span><span class="n">ggplot</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">value</span><span class="p">,</span><span class="n">fill</span><span class="o">=</span><span class="n">key</span><span class="p">))</span><span class="o">+</span><span class="w">
  </span><span class="n">geom_density</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="m">.5</span><span class="p">)</span><span class="o">+</span><span class="w">
  </span><span class="n">scale_x_log10</span><span class="p">()</span><span class="o">+</span><span class="w">
  </span><span class="n">theme_minimal</span><span class="p">()</span><span class="w">
</span></code></pre></div></div>

<p><img src="finalreport_files/figure-markdown_github/unnamed-chunk-14-2.png" alt="" /></p>

<h3 id="no-special-pre-processing-results">No special pre-processing results</h3>
<p>We can see that without any special pre-processing both models do not perform that well. In fact, both are very close to the performance of simply predicting the training set mean for the test set. Xgboost does a slightly better job of capturing variation in outcome, but even still, it cannot capture the extemely wide and flat outcome distribution.</p>

<p>In more practical terms, these results tell us that predicting the number of Kickstarter campaign backers is a tough task. Our test set RMSE implies that, on average, we should expect our predictions to be ‘off’ by about 1400 backers. Nevertheless, though our RMSE seems quite high, it tells us nothing about the practical value of such a prediction. The practical value is determined by the particular business context in which the model is deployed. It could be the case, for example, that this is good enough for making predictions about which campaigns to feature prominently on the platform’s website.</p>

<h1 id="strategy-1-naive-approach-top-50-most-common">Strategy 1: Naive Approach (Top 50 most common)</h1>

<p>Let’s see now if we can do better. 
The most basic approach to handling a large number of unique factor levels is simply to use domain expertise or business logic to collapse the levels into a smaller, more manageable subset. Similarly, in the absence of domain expertise, an analyst may collapse the factor levels into an arbitrarily smaller number of levels, usually 10 or 20. The advantage to doing so is that it reduces dimensionality (since typically R will transform factor levels into dummy variables, thus adding one dimension per unique factor level) and speeds up model training time. Such an approach generally works due to the typically Pareto-distributed counts of factor levels—in many business scenarios a small fraction of unique levels will account for a large majority of all observed values. For example, the sales of just a few products may make up the bulk of a company’s total revenue.</p>

<h1 id="downsides-to-the-naive-approach">Downsides to the naive approach</h1>

<p>The downside of the naïve approach is that we may of course be asked to analyze data we are not familiar with and so logically grouping factor levels may not be possible. Data may also be masked (i.e., pseudonymized) in order to preserve confidentiality, further obscuring the relationships among the factor levels. And perhaps more importantly, if the factor levels in the training and testing sets differ, we will encounter errors when attempting to make predictions using factor levels that the model has not encountered before.</p>

<p>For this initial experiment, we will use the number of unique categories that comprise roughy 80% of all observations. There are 159 unique campaign categories, but only 50 of those make up 80% of all observed categories in our dataset.</p>

<p>So in what follows, we will only keep the unique factor levels of the top 50 most common levels, and anything else will be converted to an “Other” category. The easiest way to do this is by using the forcats function fct_lump().</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Load in original dataset</span><span class="w">
</span><span class="n">df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">read.csv</span><span class="p">(</span><span class="s1">'kick_sample.csv'</span><span class="p">,</span><span class="w"> </span><span class="n">stringsAsFactors</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">F</span><span class="p">)</span><span class="w">

</span><span class="c1">#Keep only the top 50 categories</span><span class="w">
</span><span class="n">df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">df</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">mutate</span><span class="p">(</span><span class="n">category</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fct_lump</span><span class="p">(</span><span class="n">category</span><span class="p">,</span><span class="w"> </span><span class="m">50</span><span class="p">))</span><span class="w">

</span></code></pre></div></div>

<p>Now we rerun the previous code using this “collapsed” version of the dataset.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w"> </span><span class="c1">#BREAKUP INTO TRAINING AND TESTING</span><span class="w">
</span><span class="n">set.seed</span><span class="p">(</span><span class="m">1</span><span class="p">)</span><span class="w">
</span><span class="n">sp</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">createDataPartition</span><span class="p">(</span><span class="n">df</span><span class="o">$</span><span class="n">backers</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="o">=</span><span class="m">.8</span><span class="p">,</span><span class="w"> </span><span class="n">list</span><span class="o">=</span><span class="kc">FALSE</span><span class="p">)</span><span class="w">
</span><span class="n">train</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">df</span><span class="p">[</span><span class="n">sp</span><span class="p">,]</span><span class="w">
</span><span class="n">test</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">df</span><span class="p">[</span><span class="o">-</span><span class="n">sp</span><span class="p">,]</span><span class="w">

</span><span class="n">prep_fun</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
  </span><span class="n">x</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> 
    </span><span class="c1"># make text lower case</span><span class="w">
    </span><span class="n">str_to_lower</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> 
    </span><span class="c1"># remove non-alphanumeric symbols</span><span class="w">
    </span><span class="n">str_replace_all</span><span class="p">(</span><span class="s2">"[^[:alpha:]]"</span><span class="p">,</span><span class="w"> </span><span class="s2">" "</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> 
    </span><span class="c1"># collapse multiple spaces</span><span class="w">
    </span><span class="n">str_replace_all</span><span class="p">(</span><span class="s2">"\\s+"</span><span class="p">,</span><span class="w"> </span><span class="s2">" "</span><span class="p">)</span><span class="w">
</span><span class="p">}</span><span class="w">
</span><span class="c1">#prep_fun = tolower</span><span class="w">
</span><span class="n">tok_fun</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">word_tokenizer</span><span class="w">

</span><span class="c1">#try to fix foreign characters</span><span class="w">
</span><span class="n">df</span><span class="o">$</span><span class="n">name</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">iconv</span><span class="p">(</span><span class="n">df</span><span class="o">$</span><span class="n">name</span><span class="p">,</span><span class="w"> </span><span class="s1">'Latin-9'</span><span class="p">)</span><span class="w">

</span><span class="c1">#create training iterator</span><span class="w">
</span><span class="n">it_train</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">itoken</span><span class="p">(</span><span class="n">train</span><span class="o">$</span><span class="n">name</span><span class="p">,</span><span class="w"> 
                  </span><span class="n">preprocessor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prep_fun</span><span class="p">,</span><span class="w"> 
                  </span><span class="n">tokenizer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tok_fun</span><span class="p">,</span><span class="w"> 
                  </span><span class="n">progressbar</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w">
</span><span class="n">stop_words</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="n">tm</span><span class="o">::</span><span class="n">stopwords</span><span class="p">(</span><span class="s1">'en'</span><span class="p">),</span><span class="s2">"i"</span><span class="p">,</span><span class="w"> </span><span class="s2">"me"</span><span class="p">,</span><span class="w"> </span><span class="s2">"my"</span><span class="p">,</span><span class="w"> </span><span class="s2">"myself"</span><span class="p">,</span><span class="w"> 
               </span><span class="s2">"we"</span><span class="p">,</span><span class="w"> </span><span class="s2">"our"</span><span class="p">,</span><span class="w"> </span><span class="s2">"ours"</span><span class="p">,</span><span class="w"> </span><span class="s2">"ourselves"</span><span class="p">,</span><span class="w"> </span><span class="s2">"you"</span><span class="p">,</span><span class="w"> </span><span class="s2">"your"</span><span class="p">,</span><span class="w"> </span><span class="s2">"yours"</span><span class="p">,</span><span class="w">
               </span><span class="s1">'a'</span><span class="p">,</span><span class="w"> </span><span class="s1">'the'</span><span class="p">,</span><span class="w"> </span><span class="s1">'for'</span><span class="p">,</span><span class="w"> </span><span class="s1">'of'</span><span class="p">,</span><span class="w"> </span><span class="s1">'and'</span><span class="p">,</span><span class="w"> </span><span class="s1">'in'</span><span class="p">,</span><span class="w"> </span><span class="s1">'to'</span><span class="p">,</span><span class="w"> </span><span class="s1">'act'</span><span class="p">,</span><span class="w"> </span><span class="s1">'s'</span><span class="p">)</span><span class="w">

</span><span class="c1">#we'll use up to trigrams here</span><span class="w">
</span><span class="n">vocab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">create_vocabulary</span><span class="p">(</span><span class="n">it_train</span><span class="p">,</span><span class="w"> </span><span class="n">ngram</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">),</span><span class="w"> </span><span class="n">stopwords</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">stop_words</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#we keep 500 words max. this is already pushing memory limits of R</span><span class="w">
</span><span class="c1">#if you want to use dataframes as your data type</span><span class="w">
</span><span class="n">pruned_vocab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prune_vocabulary</span><span class="p">(</span><span class="n">vocab</span><span class="p">,</span><span class="w"> 
                                </span><span class="n">term_count_min</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">10</span><span class="p">,</span><span class="w">
                                </span><span class="n">vocab_term_max</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">500</span><span class="p">)</span><span class="w"> 

</span><span class="c1">#keep &lt;- which(nchar(pruned_vocab$term) &gt; 1)</span><span class="w">
</span><span class="c1">#pruned_vocab &lt;- pruned_vocab[keep,]</span><span class="w">
</span><span class="n">vectorizer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">vocab_vectorizer</span><span class="p">(</span><span class="n">pruned_vocab</span><span class="p">)</span><span class="w">

</span><span class="c1">#create training dtm</span><span class="w">
</span><span class="n">dtm_train</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="n">create_dtm</span><span class="p">(</span><span class="n">it_train</span><span class="p">,</span><span class="w"> </span><span class="n">vectorizer</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#DO SAME FOR TEST SET</span><span class="w">
</span><span class="n">it_test</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">itoken</span><span class="p">(</span><span class="n">test</span><span class="o">$</span><span class="n">name</span><span class="p">,</span><span class="w"> 
                  </span><span class="n">preprocessor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prep_fun</span><span class="p">,</span><span class="w"> 
                  </span><span class="n">tokenizer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tok_fun</span><span class="p">,</span><span class="w"> 
                  </span><span class="n">progressbar</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w">
</span><span class="n">stop_words</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="n">tm</span><span class="o">::</span><span class="n">stopwords</span><span class="p">(</span><span class="s1">'en'</span><span class="p">),</span><span class="s2">"i"</span><span class="p">,</span><span class="w"> </span><span class="s2">"me"</span><span class="p">,</span><span class="w"> </span><span class="s2">"my"</span><span class="p">,</span><span class="w"> </span><span class="s2">"myself"</span><span class="p">,</span><span class="w"> 
               </span><span class="s2">"we"</span><span class="p">,</span><span class="w"> </span><span class="s2">"our"</span><span class="p">,</span><span class="w"> </span><span class="s2">"ours"</span><span class="p">,</span><span class="w"> </span><span class="s2">"ourselves"</span><span class="p">,</span><span class="w"> </span><span class="s2">"you"</span><span class="p">,</span><span class="w"> </span><span class="s2">"your"</span><span class="p">,</span><span class="w"> </span><span class="s2">"yours"</span><span class="p">,</span><span class="w">
               </span><span class="s1">'a'</span><span class="p">,</span><span class="w"> </span><span class="s1">'the'</span><span class="p">,</span><span class="w"> </span><span class="s1">'for'</span><span class="p">,</span><span class="w"> </span><span class="s1">'of'</span><span class="p">,</span><span class="w"> </span><span class="s1">'and'</span><span class="p">,</span><span class="w"> </span><span class="s1">'in'</span><span class="p">,</span><span class="w"> </span><span class="s1">'to'</span><span class="p">,</span><span class="w"> </span><span class="s1">'act'</span><span class="p">,</span><span class="w"> </span><span class="s1">'s'</span><span class="p">)</span><span class="w">

</span><span class="n">vocab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">create_vocabulary</span><span class="p">(</span><span class="n">it_test</span><span class="p">,</span><span class="w"> </span><span class="n">ngram</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">),</span><span class="w"> </span><span class="n">stopwords</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">stop_words</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#do dtm for test set</span><span class="w">
</span><span class="n">dtm_test</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">create_dtm</span><span class="p">(</span><span class="n">it_test</span><span class="p">,</span><span class="w"> </span><span class="n">vectorizer</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#should be same number of columns</span><span class="w">
</span><span class="nf">dim</span><span class="p">(</span><span class="n">dtm_test</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 9999  500
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">dim</span><span class="p">(</span><span class="n">dtm_train</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 40001   500
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#create tf idf instance. apply to train then transform test based on it</span><span class="w">
</span><span class="n">model_tfidf</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">TfIdf</span><span class="o">$</span><span class="n">new</span><span class="p">()</span><span class="w">

</span><span class="c1">#fit tfidf based on train</span><span class="w">
</span><span class="n">dtm_tfidf_train</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model_tfidf</span><span class="o">$</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">dtm_train</span><span class="p">)</span><span class="w">

</span><span class="c1">#use train tfidf to transform test</span><span class="w">
</span><span class="n">dtm_tfidf_test</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model_tfidf</span><span class="o">$</span><span class="n">transform</span><span class="p">(</span><span class="n">dtm_test</span><span class="p">)</span><span class="w">

</span><span class="n">dtm_full</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">as.data.frame</span><span class="p">(</span><span class="n">as.matrix</span><span class="p">(</span><span class="n">dtm_tfidf_train</span><span class="p">),</span><span class="w"> </span><span class="n">stringsAsFactors</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">F</span><span class="p">)</span><span class="w">
</span><span class="n">dtm_full_test</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">as.data.frame</span><span class="p">(</span><span class="n">as.matrix</span><span class="p">(</span><span class="n">dtm_tfidf_test</span><span class="p">),</span><span class="w"> </span><span class="n">stringsAsFactors</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">F</span><span class="p">)</span><span class="w">

</span><span class="c1">#verify dimensions</span><span class="w">
</span><span class="nf">dim</span><span class="p">(</span><span class="n">dtm_full</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 40001   500
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#now get rid of "name" column before dividing back into train test</span><span class="w">
</span><span class="c1">#we've already turned this column into text features</span><span class="w">
</span><span class="n">train_inp</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">train</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">select</span><span class="p">(</span><span class="o">-</span><span class="n">name</span><span class="p">)</span><span class="w">
</span><span class="n">test_inp</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">test</span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">select</span><span class="p">(</span><span class="o">-</span><span class="n">name</span><span class="p">)</span><span class="w">

</span><span class="c1">#COMBINE BACK WITH ORIGINAL FEATURES. now 515 features</span><span class="w">
</span><span class="n">full_train</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">cbind</span><span class="p">(</span><span class="n">dtm_full</span><span class="p">,</span><span class="w"> </span><span class="n">train_inp</span><span class="p">)</span><span class="w">
</span><span class="n">full_test</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">cbind</span><span class="p">(</span><span class="n">dtm_full_test</span><span class="p">,</span><span class="w"> </span><span class="n">test_inp</span><span class="p">)</span><span class="w">


</span><span class="c1">#word is same as column name. need make unique! common error</span><span class="w">
</span><span class="n">colnames</span><span class="p">(</span><span class="n">full_train</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">make.unique</span><span class="p">(</span><span class="n">colnames</span><span class="p">(</span><span class="n">full_train</span><span class="p">))</span><span class="w">
</span><span class="n">colnames</span><span class="p">(</span><span class="n">full_test</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">make.unique</span><span class="p">(</span><span class="n">colnames</span><span class="p">(</span><span class="n">full_test</span><span class="p">))</span><span class="w">

</span><span class="c1">#housekeeping to free up RAM</span><span class="w">
</span><span class="n">rm</span><span class="p">(</span><span class="n">dtm_full</span><span class="p">)</span><span class="w">
</span><span class="n">rm</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span><span class="w">
</span><span class="n">rm</span><span class="p">(</span><span class="n">dtm_test</span><span class="p">)</span><span class="w">
</span><span class="n">rm</span><span class="p">(</span><span class="n">dtm_tfidf_test</span><span class="p">)</span><span class="w">
</span><span class="n">rm</span><span class="p">(</span><span class="n">dtm_tfidf_train</span><span class="p">)</span><span class="w">
</span><span class="n">rm</span><span class="p">(</span><span class="n">dtm_train</span><span class="p">)</span><span class="w">
</span><span class="n">rm</span><span class="p">(</span><span class="n">dtm_full_test</span><span class="p">)</span><span class="w">
</span><span class="n">gc</span><span class="p">()</span><span class="w">
</span></code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>##            used  (Mb) gc trigger   (Mb)  max used   (Mb)
## Ncells  3022943 161.5    5613254  299.8   5613254  299.8
## Vcells 62191143 474.5  160785797 1226.7 160780525 1226.7
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#SET UP FOLDS WITHIN TRAINING SET</span><span class="w">
</span><span class="n">set.seed</span><span class="p">(</span><span class="m">123</span><span class="p">)</span><span class="w">
</span><span class="n">myFolds</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">createFolds</span><span class="p">(</span><span class="n">full_train</span><span class="o">$</span><span class="n">backers</span><span class="p">,</span><span class="w"> </span><span class="n">k</span><span class="o">=</span><span class="m">5</span><span class="p">)</span><span class="w">

</span><span class="c1"># Create reusable trainControl object: myControl</span><span class="w">
</span><span class="n">control</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">trainControl</span><span class="p">(</span><span class="w">
  </span><span class="n">method</span><span class="o">=</span><span class="s1">'adaptive_cv'</span><span class="p">,</span><span class="w"> </span><span class="n">number</span><span class="o">=</span><span class="m">5</span><span class="p">,</span><span class="w">
  </span><span class="n">verboseIter</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,</span><span class="w">
  </span><span class="n">index</span><span class="o">=</span><span class="n">myFolds</span><span class="p">,</span><span class="w">
  </span><span class="n">preProcOptions</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"nzv"</span><span class="p">,</span><span class="w"> </span><span class="s2">"center"</span><span class="p">,</span><span class="w"> </span><span class="s2">"scale"</span><span class="p">,</span><span class="w"> </span><span class="s2">"pca"</span><span class="p">),</span><span class="w">
  </span><span class="n">returnData</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">,</span><span class="w">
   </span><span class="n">adaptive</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">min</span><span class="o">=</span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="m">0.05</span><span class="p">,</span><span class="w"> </span><span class="n">method</span><span class="o">=</span><span class="s1">'gls'</span><span class="p">,</span><span class="w"> </span><span class="n">complete</span><span class="o">=</span><span class="kc">FALSE</span><span class="p">,</span><span class="w"> </span><span class="n">search</span><span class="o">=</span><span class="s1">'random'</span><span class="p">)</span><span class="w">
  </span><span class="c1">#savePredictions = 'final'</span><span class="w">
</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Train Both Models</span><span class="w">
</span><span class="n">set.seed</span><span class="p">(</span><span class="m">1</span><span class="p">)</span><span class="w">
</span><span class="n">glm_model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">train</span><span class="p">(</span><span class="n">backers</span><span class="w"> </span><span class="o">~</span><span class="n">.</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="o">=</span><span class="w"> </span><span class="n">full_train</span><span class="p">,</span><span class="w"> </span><span class="n">method</span><span class="o">=</span><span class="s1">'glmnet'</span><span class="p">,</span><span class="w"> </span><span class="n">metric</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"RMSE"</span><span class="p">,</span><span class="w"> </span><span class="n">trControl</span><span class="o">=</span><span class="n">control</span><span class="p">)</span><span class="w">

</span><span class="n">set.seed</span><span class="p">(</span><span class="m">1</span><span class="p">)</span><span class="w">
</span><span class="n">xg_model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">train</span><span class="p">(</span><span class="n">backers</span><span class="w"> </span><span class="o">~</span><span class="n">.</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="o">=</span><span class="w"> </span><span class="n">full_train</span><span class="p">,</span><span class="w"> </span><span class="n">method</span><span class="o">=</span><span class="s1">'xgbTree'</span><span class="p">,</span><span class="w"> </span><span class="n">metric</span><span class="o">=</span><span class="s1">'RMSE'</span><span class="p">,</span><span class="w">
                  </span><span class="n">trControl</span><span class="o">=</span><span class="n">control</span><span class="p">,</span><span class="w"> </span><span class="n">tuneLength</span><span class="o">=</span><span class="m">2</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<h1 id="examine-predictions-of-naive-approach">Examine predictions of Naive Approach</h1>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">Metrics</span><span class="p">)</span><span class="w">
</span><span class="c1">#GET PREDICTIONS</span><span class="w">
</span><span class="n">prd</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">data.frame</span><span class="p">(</span><span class="n">predictions_glm</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">predict</span><span class="p">(</span><span class="n">glm_model</span><span class="p">,</span><span class="w"> </span><span class="n">full_test</span><span class="p">),</span><span class="w">
                  </span><span class="n">predictions_xg</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">predict</span><span class="p">(</span><span class="n">xg_model</span><span class="p">,</span><span class="w"> </span><span class="n">full_test</span><span class="p">),</span><span class="w">
                  </span><span class="n">actuals</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">full_test</span><span class="o">$</span><span class="n">backers</span><span class="p">)</span><span class="w">

</span><span class="c1">#calculate rmse GLMNET</span><span class="w">
</span><span class="n">rmse</span><span class="p">(</span><span class="n">prd</span><span class="o">$</span><span class="n">actuals</span><span class="p">,</span><span class="w"> </span><span class="n">prd</span><span class="o">$</span><span class="n">predictions_glm</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 1415.99
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#calculate rmse XG</span><span class="w">
</span><span class="n">rmse</span><span class="p">(</span><span class="n">prd</span><span class="o">$</span><span class="n">actuals</span><span class="p">,</span><span class="w"> </span><span class="n">prd</span><span class="o">$</span><span class="n">predictions_xg</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 1412.976
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#check against training mean</span><span class="w">
</span><span class="n">rmse</span><span class="p">(</span><span class="n">prd</span><span class="o">$</span><span class="n">actuals</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">full_train</span><span class="o">$</span><span class="n">backers</span><span class="p">))</span><span class="w">
</span></code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 1419.206
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#plot both on top </span><span class="w">
</span><span class="n">prd</span><span class="o">%&gt;%</span><span class="w">
</span><span class="n">ggplot</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">actuals</span><span class="p">,</span><span class="w"> </span><span class="n">predictions_glm</span><span class="p">))</span><span class="o">+</span><span class="w">
  </span><span class="n">geom_point</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="m">.2</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">)</span><span class="o">+</span><span class="w">
  </span><span class="n">geom_point</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">actuals</span><span class="p">,</span><span class="w"> </span><span class="n">predictions_xg</span><span class="p">),</span><span class="n">size</span><span class="o">=</span><span class="m">1</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="m">.2</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">)</span><span class="o">+</span><span class="w">
  </span><span class="n">geom_abline</span><span class="p">(</span><span class="n">slope</span><span class="o">=</span><span class="m">1</span><span class="p">)</span><span class="o">+</span><span class="w">
  </span><span class="n">scale_x_log10</span><span class="p">()</span><span class="o">+</span><span class="w">
  </span><span class="n">scale_y_log10</span><span class="p">()</span><span class="o">+</span><span class="w">
  </span><span class="n">theme_minimal</span><span class="p">()</span><span class="w">
</span></code></pre></div></div>

<p><img src="finalreport_files/figure-markdown_github/unnamed-chunk-18-1.png" alt="" /></p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#density plot</span><span class="w">
</span><span class="n">prd</span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">gather</span><span class="p">()</span><span class="o">%&gt;%</span><span class="w">
</span><span class="n">ggplot</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">value</span><span class="p">,</span><span class="n">fill</span><span class="o">=</span><span class="n">key</span><span class="p">))</span><span class="o">+</span><span class="w">
  </span><span class="n">geom_density</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="m">.5</span><span class="p">)</span><span class="o">+</span><span class="w">
  </span><span class="n">scale_x_log10</span><span class="p">()</span><span class="o">+</span><span class="w">
  </span><span class="n">theme_minimal</span><span class="p">()</span><span class="w">
</span></code></pre></div></div>

<p><img src="finalreport_files/figure-markdown_github/unnamed-chunk-18-2.png" alt="" /></p>

<h3 id="top-n-collapsing-results">Top N collapsing results</h3>

<p>Overall, the xgboost and glm models still struggle at predicting the wide variety of Kickstarter campaign backers. 
But when we collapse categories it seems to benefit xgboost more than glm, judged by the very slight RMSE reduction for xgboost (1413 to 1412). 
So one takeaway is that by collapsing categories we can likely get (very slight) immediate predictive improvements when using boosting algorithms.</p>

<h1 id="strategy-2-impact-coding-using-the-r-package-vtreat">Strategy 2: Impact Coding using the R package vtreat</h1>

<p>This approach to dealing with high-cardinality categorical predictors is based on the work of Mount &amp; Zumel (2018)<sup id="fnref:2:1"><a href="#fn:2" class="footnote">2</a></sup> and the main functionality is included in the R package <em>vtreat</em>. The purpose of the package is to use a data frame to collect statistics that can then be used to replace the original categorical data (this process also incidentally solves the problem of missing values).</p>

<p>Essentially, the “impact” of a particular level is the difference in the expected value of the outcome given the level and the expected value of the unconditional outcome. 
<img src="./pics/formula.png" alt="determing impact score" class="img-responsive" /></p>

<p>The result is a numeric value that will give the analyst a rough idea of how important a particular level is. For example, a level with a very large impact score may be worth examining since this level’s average outcome is much higher than the overall average.</p>

<h1 id="benefits-of-impact-coding">Benefits of Impact Coding</h1>

<p>Replacing the factor levels with numeric values two main advantages. First, it avoids creating extraneous dummy variables. Second, the issue of new levels arising in the test set is resolved. Regarding the first advantage, the package will actually create dummy variables for the most prevalent factor levels so that analysts can use these dummy variables to create potential interaction terms.</p>

<p>The package also has deals with missing values by using the mean value for the non-missing data and by creating a dummy variable is_missing, which can often times be useful in modeling when data are missing systematically. According to the package authors, in a business setting, missing data is often a reflection of where the data came from, so if we encode the missingness into a new variable we may gain some useful information that our models can learn from. Finally, the package also can perform single variable regressions of the factor level on the outcome in order to aid variable selection efforts. The user can set a significance threshold and factor levels which do not meet it are pooled together instead of kept as separate dummy variables (often useful in tree-based algorithms).</p>

<h1 id="avoiding-nested-model-bias">Avoiding Nested model Bias</h1>

<p>One key issue when determining the impact code of a particular categorical factor level is that the analyst must be careful to avoid “nested model bias.” Nested model bias occurs when a model is trained on a sample of data and then is later is applied on the same data. Because the same data was used for building and testing the model, performance metrics do not give an accurate idea of out of sample performance and we will have likely overfit to the training data.</p>

<p>Here’s an analogy to explain why this is a problem. Imagine you wish to gauge the math skills of a young student using a final exam. First, one month before the final exam you give him several old calculus practice exams to study with. Then, on the day of the test, you give him the exact same practice exams in the exact same order. Would you be confident in the student’s ability to solve new—but slightly different—calculus problems? What if the student has merely memorized the answers to the practice exams but fails to be able to generalize the important calculus concepts and apply them in novel situations? How would we know? In this case, we would say he has “overfit” his learning to the practice exams and his test performance is not actually indicative of his skill in solving calculus problems (i.e., it’s overly optimistic). It is this kind of situation we also wish to avoid when training and evaluating our machine learning models. We have two main ways to deal with this issue and they are both supported by vtreat.</p>

<p>The first solution when computing the impact code is to divide the data into a normal training and testing set. However, then one divides the training set into further “folds” or pieces: for all but one of these folds we will determine the difference in expected values and then “apply” the computation to the “out of sample” fold not used in calculating the difference in expected values. We repeat this until we have applied the calculation to every fold and then average the results among all folds. The final result is an ‘impact score’ that is less biased when later on a model is trained and tested on out of sample data. The mapping (converting the factor levels into numeric values) of these impact scores is then reproduced on the test set data. The test set impact scores will have been transformed only using information available in the training set, which simulates what would happen were we to deploy this model in the real world on new data that were previously unseen by our model.</p>

<p>The other solution is to divide our data into three sets: training, testing, and evaluation. This image below shows the workflow (from Mount &amp; Zumel 2018 <sup id="fnref:2:2"><a href="#fn:2" class="footnote">2</a></sup>)
<img src="./pics/flow.png" alt="vtreat workflow" class="img-responsive" />
In the evaluation set, we compute the statistics needed for the impact score. Then, we apply the appropriate “treatment” (based on the expected differences in our evaluation set) to the training and testing sets. This again avoids the problem of having our impact scores unfairly reflect characteristics of the test set, which would lead us to believe the model’s performance is really better than it is on unseen data. The downside of this approach is that you lose some portion of your data to the evaluation set, which is typically 10-20% of all data. So in cases where you have less data, the cross-validation approach may be better.
In order to avoid setting up three data partitions, we will go the cross-validation route.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">vtreat</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">caret</span><span class="p">)</span><span class="w">
</span><span class="n">df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">read.csv</span><span class="p">(</span><span class="s1">'kick_sample.csv'</span><span class="p">,</span><span class="w"> </span><span class="n">stringsAsFactors</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">F</span><span class="p">)</span><span class="w">

</span><span class="c1">#BREAK UP INTO TRAINING AND TESTING</span><span class="w">
</span><span class="n">set.seed</span><span class="p">(</span><span class="m">1</span><span class="p">)</span><span class="w">
</span><span class="n">sp</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">createDataPartition</span><span class="p">(</span><span class="n">df</span><span class="o">$</span><span class="n">backers</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="o">=</span><span class="m">.8</span><span class="p">,</span><span class="w"> </span><span class="n">list</span><span class="o">=</span><span class="kc">FALSE</span><span class="p">)</span><span class="w">
</span><span class="n">train</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">df</span><span class="p">[</span><span class="n">sp</span><span class="p">,]</span><span class="w">
</span><span class="n">test</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">df</span><span class="p">[</span><span class="o">-</span><span class="n">sp</span><span class="p">,]</span><span class="w">
</span></code></pre></div></div>

<h1 id="text-processing">Text processing</h1>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">prep_fun</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
  </span><span class="n">x</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> 
    </span><span class="c1"># make text lower case</span><span class="w">
    </span><span class="n">str_to_lower</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> 
    </span><span class="c1"># remove non-alphanumeric symbols</span><span class="w">
    </span><span class="n">str_replace_all</span><span class="p">(</span><span class="s2">"[^[:alpha:]]"</span><span class="p">,</span><span class="w"> </span><span class="s2">" "</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> 
    </span><span class="c1"># collapse multiple spaces</span><span class="w">
    </span><span class="n">str_replace_all</span><span class="p">(</span><span class="s2">"\\s+"</span><span class="p">,</span><span class="w"> </span><span class="s2">" "</span><span class="p">)</span><span class="w">
</span><span class="p">}</span><span class="w">
</span><span class="c1">#prep_fun = tolower</span><span class="w">
</span><span class="n">tok_fun</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">word_tokenizer</span><span class="w">

</span><span class="c1">#try to fix foreign characters</span><span class="w">
</span><span class="n">df</span><span class="o">$</span><span class="n">name</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">iconv</span><span class="p">(</span><span class="n">df</span><span class="o">$</span><span class="n">name</span><span class="p">,</span><span class="w"> </span><span class="s1">'Latin-9'</span><span class="p">)</span><span class="w">

</span><span class="c1">#create training iterator</span><span class="w">
</span><span class="n">it_train</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">itoken</span><span class="p">(</span><span class="n">train</span><span class="o">$</span><span class="n">name</span><span class="p">,</span><span class="w"> 
                  </span><span class="n">preprocessor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prep_fun</span><span class="p">,</span><span class="w"> 
                  </span><span class="n">tokenizer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tok_fun</span><span class="p">,</span><span class="w"> 
                  </span><span class="n">progressbar</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w">
</span><span class="n">stop_words</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="n">tm</span><span class="o">::</span><span class="n">stopwords</span><span class="p">(</span><span class="s1">'en'</span><span class="p">),</span><span class="s2">"i"</span><span class="p">,</span><span class="w"> </span><span class="s2">"me"</span><span class="p">,</span><span class="w"> </span><span class="s2">"my"</span><span class="p">,</span><span class="w"> </span><span class="s2">"myself"</span><span class="p">,</span><span class="w"> 
               </span><span class="s2">"we"</span><span class="p">,</span><span class="w"> </span><span class="s2">"our"</span><span class="p">,</span><span class="w"> </span><span class="s2">"ours"</span><span class="p">,</span><span class="w"> </span><span class="s2">"ourselves"</span><span class="p">,</span><span class="w"> </span><span class="s2">"you"</span><span class="p">,</span><span class="w"> </span><span class="s2">"your"</span><span class="p">,</span><span class="w"> </span><span class="s2">"yours"</span><span class="p">,</span><span class="w">
               </span><span class="s1">'a'</span><span class="p">,</span><span class="w"> </span><span class="s1">'the'</span><span class="p">,</span><span class="w"> </span><span class="s1">'for'</span><span class="p">,</span><span class="w"> </span><span class="s1">'of'</span><span class="p">,</span><span class="w"> </span><span class="s1">'and'</span><span class="p">,</span><span class="w"> </span><span class="s1">'in'</span><span class="p">,</span><span class="w"> </span><span class="s1">'to'</span><span class="p">,</span><span class="w"> </span><span class="s1">'act'</span><span class="p">,</span><span class="w"> </span><span class="s1">'s'</span><span class="p">)</span><span class="w">

</span><span class="c1">#we'll use up to trigrams here</span><span class="w">
</span><span class="n">vocab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">create_vocabulary</span><span class="p">(</span><span class="n">it_train</span><span class="p">,</span><span class="w"> </span><span class="n">ngram</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">),</span><span class="w"> </span><span class="n">stopwords</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">stop_words</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#we keep 500 words max. this is already pushing memory limits of R</span><span class="w">
</span><span class="n">pruned_vocab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prune_vocabulary</span><span class="p">(</span><span class="n">vocab</span><span class="p">,</span><span class="w"> 
                                </span><span class="n">term_count_min</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">10</span><span class="p">,</span><span class="w">
                                </span><span class="n">vocab_term_max</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">500</span><span class="p">)</span><span class="w"> 

</span><span class="c1">#keep &lt;- which(nchar(pruned_vocab$term) &gt; 1)</span><span class="w">
</span><span class="c1">#pruned_vocab &lt;- pruned_vocab[keep,]</span><span class="w">
</span><span class="n">vectorizer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">vocab_vectorizer</span><span class="p">(</span><span class="n">pruned_vocab</span><span class="p">)</span><span class="w">

</span><span class="c1">#create training dtm</span><span class="w">
</span><span class="n">dtm_train</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="n">create_dtm</span><span class="p">(</span><span class="n">it_train</span><span class="p">,</span><span class="w"> </span><span class="n">vectorizer</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Now rinse and repeat for the test set</span><span class="w">
</span><span class="n">it_test</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">itoken</span><span class="p">(</span><span class="n">test</span><span class="o">$</span><span class="n">name</span><span class="p">,</span><span class="w"> 
                  </span><span class="n">preprocessor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prep_fun</span><span class="p">,</span><span class="w"> 
                  </span><span class="n">tokenizer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tok_fun</span><span class="p">,</span><span class="w"> 
                  </span><span class="n">progressbar</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w">
</span><span class="n">stop_words</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="n">tm</span><span class="o">::</span><span class="n">stopwords</span><span class="p">(</span><span class="s1">'en'</span><span class="p">),</span><span class="s2">"i"</span><span class="p">,</span><span class="w"> </span><span class="s2">"me"</span><span class="p">,</span><span class="w"> </span><span class="s2">"my"</span><span class="p">,</span><span class="w"> </span><span class="s2">"myself"</span><span class="p">,</span><span class="w"> 
               </span><span class="s2">"we"</span><span class="p">,</span><span class="w"> </span><span class="s2">"our"</span><span class="p">,</span><span class="w"> </span><span class="s2">"ours"</span><span class="p">,</span><span class="w"> </span><span class="s2">"ourselves"</span><span class="p">,</span><span class="w"> </span><span class="s2">"you"</span><span class="p">,</span><span class="w"> </span><span class="s2">"your"</span><span class="p">,</span><span class="w"> </span><span class="s2">"yours"</span><span class="p">,</span><span class="w">
               </span><span class="s1">'a'</span><span class="p">,</span><span class="w"> </span><span class="s1">'the'</span><span class="p">,</span><span class="w"> </span><span class="s1">'for'</span><span class="p">,</span><span class="w"> </span><span class="s1">'of'</span><span class="p">,</span><span class="w"> </span><span class="s1">'and'</span><span class="p">,</span><span class="w"> </span><span class="s1">'in'</span><span class="p">,</span><span class="w"> </span><span class="s1">'to'</span><span class="p">,</span><span class="w"> </span><span class="s1">'act'</span><span class="p">,</span><span class="w"> </span><span class="s1">'s'</span><span class="p">)</span><span class="w">

</span><span class="n">vocab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">create_vocabulary</span><span class="p">(</span><span class="n">it_test</span><span class="p">,</span><span class="w"> </span><span class="n">ngram</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">),</span><span class="w"> </span><span class="n">stopwords</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">stop_words</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#do dtm for test set</span><span class="w">
</span><span class="n">dtm_test</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">create_dtm</span><span class="p">(</span><span class="n">it_test</span><span class="p">,</span><span class="w"> </span><span class="n">vectorizer</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#should be same number of columns</span><span class="w">
</span><span class="nf">dim</span><span class="p">(</span><span class="n">dtm_test</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 9999  500
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">dim</span><span class="p">(</span><span class="n">dtm_train</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 40001   500
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#create tf idf instance. apply to train then transform test based on it</span><span class="w">
</span><span class="n">model_tfidf</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">TfIdf</span><span class="o">$</span><span class="n">new</span><span class="p">()</span><span class="w">

</span><span class="c1">#fit tfidf based on train</span><span class="w">
</span><span class="n">dtm_tfidf_train</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model_tfidf</span><span class="o">$</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">dtm_train</span><span class="p">)</span><span class="w">

</span><span class="c1">#use train tfidf to transform test</span><span class="w">
</span><span class="n">dtm_tfidf_test</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model_tfidf</span><span class="o">$</span><span class="n">transform</span><span class="p">(</span><span class="n">dtm_test</span><span class="p">)</span><span class="w">

</span><span class="n">dtm_full</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">as.data.frame</span><span class="p">(</span><span class="n">as.matrix</span><span class="p">(</span><span class="n">dtm_tfidf_train</span><span class="p">),</span><span class="w"> </span><span class="n">stringsAsFactors</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">F</span><span class="p">)</span><span class="w">
</span><span class="n">dtm_full_test</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">as.data.frame</span><span class="p">(</span><span class="n">as.matrix</span><span class="p">(</span><span class="n">dtm_tfidf_test</span><span class="p">),</span><span class="w"> </span><span class="n">stringsAsFactors</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">F</span><span class="p">)</span><span class="w">


</span><span class="nf">dim</span><span class="p">(</span><span class="n">dtm_full</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 40001   500
</code></pre></div></div>

<h1 id="using-vtreats-crossframe-procedure-to-estimate-impact-scores">Using Vtreat’s “crossframe” procedure to estimate impact scores</h1>

<p>The language used by vtreat is confusing at first, but a “crossframe” experiment is simply using a cross-validation procedure to estimate impact scores.
If we didn’t want to use this approach, we could also split our data into three sets: training, testing, and calibration. The ‘calibration’ set would be used solely to estimate the impact scores and help us to convert the categorical levels into numeric values.
Again, we don’t want to do this using the testing set because it would then invalidate our performance estimates since we would then be estimating the model’s performance
using the same data used to estimate the impact scores.</p>

<p>If we reduce our threshold for prune significance due to multiple comparison (similar to a Bonferroni adjustment), we will end up with 59 predictors from our original 15, not including our text features.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#this conducts the 3 fold cross val</span><span class="w">
</span><span class="n">cfe</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">mkCrossFrameNExperiment</span><span class="p">(</span><span class="n">train</span><span class="p">,</span><span class="w"> </span><span class="n">setdiff</span><span class="p">(</span><span class="n">colnames</span><span class="p">(</span><span class="n">train</span><span class="p">),</span><span class="w"> </span><span class="s1">'name'</span><span class="p">),</span><span class="w"> </span><span class="s1">'backers'</span><span class="p">,</span><span class="w">
                               </span><span class="n">rareCount</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">50</span><span class="p">,</span><span class="w">
                               </span><span class="n">minFraction</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">.01</span><span class="p">,</span><span class="w">
                               </span><span class="n">ncross</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">5</span><span class="p">,</span><span class="w">
                               </span><span class="n">verbose</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] "vtreat 1.3.2 start initial treatment design Sun Mar 03 09:09:46 2019"
## [1] " start cross frame work Sun Mar 03 09:09:56 2019"
## [1] " vtreat::mkCrossFrameNExperiment done Sun Mar 03 09:10:02 2019"
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#adjust significance level of predictor downwards to compensate for multiple comparisons</span><span class="w">
</span><span class="n">psig</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1</span><span class="o">/</span><span class="n">ncol</span><span class="p">(</span><span class="n">train</span><span class="p">)</span><span class="w"> 


</span><span class="c1">#apply our results to the training and testing sets using prepare()</span><span class="w">
</span><span class="n">train_treat</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">prepare</span><span class="p">(</span><span class="n">treatments</span><span class="p">,</span><span class="w"> </span><span class="n">train</span><span class="p">,</span><span class="w"> </span><span class="n">pruneSig</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">psig</span><span class="p">)</span><span class="w">
</span><span class="n">test_treat</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">prepare</span><span class="p">(</span><span class="n">treatments</span><span class="p">,</span><span class="w"> </span><span class="n">test</span><span class="p">,</span><span class="w"> </span><span class="n">pruneSig</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">psig</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p>We use our normal adaptive resampling approach as we did earlier.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#SET UP FOLDS WITHIN TRAINING SET</span><span class="w">
</span><span class="n">set.seed</span><span class="p">(</span><span class="m">123</span><span class="p">)</span><span class="w">
</span><span class="n">myFolds</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">createFolds</span><span class="p">(</span><span class="n">train_treat</span><span class="o">$</span><span class="n">backers</span><span class="p">,</span><span class="w"> </span><span class="n">k</span><span class="o">=</span><span class="m">5</span><span class="p">)</span><span class="w">

</span><span class="c1"># Create reusable trainControl object: myControl</span><span class="w">
</span><span class="n">control</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">trainControl</span><span class="p">(</span><span class="w">
  </span><span class="n">method</span><span class="o">=</span><span class="s1">'adaptive_cv'</span><span class="p">,</span><span class="w"> </span><span class="n">number</span><span class="o">=</span><span class="m">5</span><span class="p">,</span><span class="w">
  </span><span class="n">verboseIter</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,</span><span class="w">
  </span><span class="n">index</span><span class="o">=</span><span class="n">myFolds</span><span class="p">,</span><span class="w">
  </span><span class="c1">#preProcOptions = c("nzv", "center", "scale", "pca"),</span><span class="w">
  </span><span class="n">returnData</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">,</span><span class="w">
   </span><span class="n">adaptive</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">min</span><span class="o">=</span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="m">0.20</span><span class="p">,</span><span class="w"> </span><span class="n">method</span><span class="o">=</span><span class="s1">'gls'</span><span class="p">,</span><span class="w"> </span><span class="n">complete</span><span class="o">=</span><span class="kc">FALSE</span><span class="p">,</span><span class="w"> </span><span class="n">search</span><span class="o">=</span><span class="s1">'random'</span><span class="p">)</span><span class="w">
  </span><span class="c1">#savePredictions = 'final'</span><span class="w">
</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p>Now we add back our vtreated data to the text features.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#COMBINE BACK WITH text features. now 559 features</span><span class="w">
</span><span class="n">full_train</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">cbind</span><span class="p">(</span><span class="n">dtm_full</span><span class="p">,</span><span class="w"> </span><span class="n">train_treat</span><span class="p">)</span><span class="w">
</span><span class="n">full_test</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">cbind</span><span class="p">(</span><span class="n">dtm_full_test</span><span class="p">,</span><span class="w"> </span><span class="n">test_treat</span><span class="p">)</span><span class="w">

</span><span class="c1">#word is same as column name. need make unique! common error</span><span class="w">
</span><span class="n">colnames</span><span class="p">(</span><span class="n">full_train</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">make.unique</span><span class="p">(</span><span class="n">colnames</span><span class="p">(</span><span class="n">full_train</span><span class="p">))</span><span class="w">
</span><span class="n">colnames</span><span class="p">(</span><span class="n">full_test</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">make.unique</span><span class="p">(</span><span class="n">colnames</span><span class="p">(</span><span class="n">full_test</span><span class="p">))</span><span class="w">

</span><span class="n">rm</span><span class="p">(</span><span class="n">dtm_full</span><span class="p">)</span><span class="w">
</span><span class="n">rm</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span><span class="w">
</span><span class="n">rm</span><span class="p">(</span><span class="n">dtm_test</span><span class="p">)</span><span class="w">
</span><span class="n">rm</span><span class="p">(</span><span class="n">dtm_tfidf_test</span><span class="p">)</span><span class="w">
</span><span class="n">rm</span><span class="p">(</span><span class="n">dtm_tfidf_train</span><span class="p">)</span><span class="w">
</span><span class="n">rm</span><span class="p">(</span><span class="n">dtm_train</span><span class="p">)</span><span class="w">
</span><span class="n">rm</span><span class="p">(</span><span class="n">dtm_full_test</span><span class="p">)</span><span class="w">
</span><span class="n">gc</span><span class="p">()</span><span class="w">
</span></code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>##            used  (Mb) gc trigger   (Mb)  max used   (Mb)
## Ncells  3057352 163.3    5613254  299.8   5613254  299.8
## Vcells 65228161 497.7  160785797 1226.7 160785751 1226.7
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">glm_model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">train</span><span class="p">(</span><span class="n">backers</span><span class="w"> </span><span class="o">~</span><span class="n">.</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="o">=</span><span class="w"> </span><span class="n">train_treat</span><span class="p">,</span><span class="w"> </span><span class="n">method</span><span class="o">=</span><span class="s1">'glmnet'</span><span class="p">,</span><span class="w"> </span><span class="n">metric</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"RMSE"</span><span class="p">,</span><span class="w"> </span><span class="n">trControl</span><span class="o">=</span><span class="n">control</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">xg_model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">train</span><span class="p">(</span><span class="n">backers</span><span class="w"> </span><span class="o">~</span><span class="n">.</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="o">=</span><span class="w"> </span><span class="n">train_treat</span><span class="p">,</span><span class="w"> </span><span class="n">method</span><span class="o">=</span><span class="s1">'xgbTree'</span><span class="p">,</span><span class="w"> </span><span class="n">metric</span><span class="o">=</span><span class="s1">'RMSE'</span><span class="p">,</span><span class="w">
                  </span><span class="n">trControl</span><span class="o">=</span><span class="n">control</span><span class="p">,</span><span class="w"> </span><span class="n">tuneLength</span><span class="o">=</span><span class="m">2</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">varImp</span><span class="p">(</span><span class="n">glm_model</span><span class="p">,</span><span class="w"> </span><span class="n">scale</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## glmnet variable importance
## 
##   only 20 most important variables shown (out of 58)
## 
##                                   Overall
## country_catP                    100.00000
## word_count_clean                  9.64095
## category_catN                     5.63701
## dow_deadline_catN                 1.71408
## main_category_catN                0.66561
## total_chars_clean                 0.47224
## country_catD                      0.21596
## country_catN                      0.10875
## main_category_catD                0.02827
## category_lev_x_Music              0.00000
## category_lev_x_Film_Video         0.00000
## category_lev_x_Apparel            0.00000
## main_category_lev_x_Photography   0.00000
## currency_catN                     0.00000
## category_lev_x_Crafts             0.00000
## main_category_lev_x_Music         0.00000
## currency_lev_x_EUR                0.00000
## category_lev_x_Technology         0.00000
## main_category_lev_x_Publishing    0.00000
## yr_deadline_clean                 0.00000
</code></pre></div></div>

<h1 id="interpreting-vtreats-output">Interpreting Vtreat’s output</h1>

<p>After running our ‘cross frame’ and then applying the treatment procedure to our data we end up with three new features for each categorical predictor.
These are marked with certain codes.</p>
<ul>
  <li>P – Prevalence</li>
  <li>N - Impact Score</li>
  <li>D – Within group Deviation</li>
</ul>

<p>So for example, our glmnet model latched on to the prevalence (numeric frequency) of the country (‘country_catP’) as the most important predictor.
Next it used the impact score of the category column (‘category_catN’) as the second most important predictor.
Notice that vtreat still creates dummies for most frequent levels (which they claim are favored for tree-based methods). These show up as ‘category_lev_x_Music’</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">varImp</span><span class="p">(</span><span class="n">xg_model</span><span class="p">,</span><span class="w"> </span><span class="n">scale</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## xgbTree variable importance
## 
##   only 20 most important variables shown (out of 58)
## 
##                              Overall
## category_catN               100.0000
## main_category_catD            7.7847
## word_count_clean              2.7065
## country_catD                  2.6653
## country_catN                  2.6389
## total_chars_clean             1.7642
## dow_deadline_catN             1.4014
## yr_deadline_clean             1.3780
## category_catP                 1.2332
## category_catD                 0.9531
## dow_deadline_catP             0.5248
## dow_deadline_catD             0.2941
## country_catP                  0.2930
## currency_lev_x_USD            0.0000
## main_category_lev_x_Fashion   0.0000
## category_lev_x_Photography    0.0000
## category_lev_x_Art            0.0000
## category_lev_x_Fiction        0.0000
## main_category_lev_x_Art       0.0000
## category_lev_x_Apparel        0.0000
</code></pre></div></div>

<h1 id="view-the-predictive-results">View the Predictive results</h1>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">Metrics</span><span class="p">)</span><span class="w">
</span><span class="c1">#GET PREDICTIONS</span><span class="w">
</span><span class="n">prd</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">data.frame</span><span class="p">(</span><span class="n">predictions_glm</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">predict</span><span class="p">(</span><span class="n">glm_model</span><span class="p">,</span><span class="w"> </span><span class="n">test_treat</span><span class="p">),</span><span class="w">
                  </span><span class="n">predictions_xg</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">predict</span><span class="p">(</span><span class="n">xg_model</span><span class="p">,</span><span class="w"> </span><span class="n">test_treat</span><span class="p">),</span><span class="w">
                  </span><span class="n">actuals</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">test_treat</span><span class="o">$</span><span class="n">backers</span><span class="p">)</span><span class="w">

</span><span class="c1">#deal with negative predictions by turning to 0</span><span class="w">
</span><span class="n">prd</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">prd</span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">mutate</span><span class="p">(</span><span class="n">predictions_glm</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ifelse</span><span class="p">(</span><span class="n">predictions_glm</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">predictions_glm</span><span class="p">))</span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">mutate</span><span class="p">(</span><span class="n">predictions_xg</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ifelse</span><span class="p">(</span><span class="n">predictions_xg</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">predictions_xg</span><span class="p">))</span><span class="w">

</span><span class="c1">#calculate rmse GLMNET</span><span class="w">
</span><span class="n">rmse</span><span class="p">(</span><span class="n">prd</span><span class="o">$</span><span class="n">actuals</span><span class="p">,</span><span class="w"> </span><span class="n">prd</span><span class="o">$</span><span class="n">predictions_glm</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 1414.509
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#calculate rmse xg</span><span class="w">
</span><span class="n">rmse</span><span class="p">(</span><span class="n">prd</span><span class="o">$</span><span class="n">actuals</span><span class="p">,</span><span class="w"> </span><span class="n">prd</span><span class="o">$</span><span class="n">predictions_xg</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 1414.316
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#check against training mean</span><span class="w">
</span><span class="n">rmse</span><span class="p">(</span><span class="n">prd</span><span class="o">$</span><span class="n">actuals</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">train_treat</span><span class="o">$</span><span class="n">backers</span><span class="p">))</span><span class="w">
</span></code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 1419.206
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#plot both on top </span><span class="w">
</span><span class="n">prd</span><span class="o">%&gt;%</span><span class="w">
</span><span class="n">ggplot</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">actuals</span><span class="p">,</span><span class="w"> </span><span class="n">predictions_glm</span><span class="p">))</span><span class="o">+</span><span class="w">
  </span><span class="n">geom_point</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="m">.2</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">)</span><span class="o">+</span><span class="w">
  </span><span class="n">geom_point</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">actuals</span><span class="p">,</span><span class="w"> </span><span class="n">predictions_xg</span><span class="p">),</span><span class="n">size</span><span class="o">=</span><span class="m">1</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="m">.2</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">)</span><span class="o">+</span><span class="w">
  </span><span class="n">geom_abline</span><span class="p">(</span><span class="n">slope</span><span class="o">=</span><span class="m">1</span><span class="p">)</span><span class="o">+</span><span class="w">
  </span><span class="n">scale_x_log10</span><span class="p">()</span><span class="o">+</span><span class="w">
  </span><span class="n">scale_y_log10</span><span class="p">()</span><span class="o">+</span><span class="w">
  </span><span class="n">labs</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">'Vtreated data'</span><span class="p">,</span><span class="w"> </span><span class="n">subtitle</span><span class="o">=</span><span class="s1">'Glmnet (blue) vs. xgBoost (red)'</span><span class="p">)</span><span class="o">+</span><span class="w">
  </span><span class="n">theme_minimal</span><span class="p">()</span><span class="w">
</span></code></pre></div></div>

<p><img src="finalreport_files/figure-markdown_github/unnamed-chunk-28-1.png" alt="" /></p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#density plot</span><span class="w">
</span><span class="n">prd</span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">gather</span><span class="p">()</span><span class="o">%&gt;%</span><span class="w">
</span><span class="n">ggplot</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">value</span><span class="p">,</span><span class="n">fill</span><span class="o">=</span><span class="n">key</span><span class="p">))</span><span class="o">+</span><span class="w">
  </span><span class="n">geom_density</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="m">.5</span><span class="p">)</span><span class="o">+</span><span class="w">
  </span><span class="n">scale_x_log10</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="n">scales</span><span class="o">::</span><span class="n">comma</span><span class="p">)</span><span class="o">+</span><span class="w">
  </span><span class="n">labs</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">'Vtreated data'</span><span class="p">,</span><span class="w"> </span><span class="n">subtitle</span><span class="o">=</span><span class="s1">'Glmnet (green) vs. xgBoost (blue) vs. Actual (red)'</span><span class="p">)</span><span class="o">+</span><span class="w">
  </span><span class="n">theme_minimal</span><span class="p">()</span><span class="w">
</span></code></pre></div></div>

<p><img src="finalreport_files/figure-markdown_github/unnamed-chunk-28-2.png" alt="" /></p>

<h3 id="vtreat-results">Vtreat results</h3>
<p>Interestingly here both the xgboost and the glm models appear to be making very similar predictions. But both models cannot seem to predict the very low or high values.
For me, I take this as evidence that categorical predictors are actually quite useful to xgboost and tree-based methods. By converting the categorical predictors into numeric versions, we seem to have lost the ability to make extremely high or low predictions.
So perhaps the takeaway here is that vtreat should be used with caution with any tree-based method. In fact, the authors of vtreat state explicitly that they envision their approach to be used with LASSO, where there is a built-in variable selection mechanism to deal with the creation of the new numeric predictors.</p>

<h1 id="strategy-3-feature-hashing">Strategy 3: Feature Hashing</h1>

<p>The final method borrows the idea of a hashing function from computer science and attempts to deal with high-cardinality categorical predictors by means of memory and speed savings at the expense of model interpretability.</p>

<p>The method works by mapping our factor levels to numeric indices, which are then used as binary features. For each categorical level, a hashing function is used to transform the text into a numeric representation (the featureHashing package in R uses the murmurhash3 hashing function). A hash is any function that can be used to map data of an arbitrary size to a fixed size. Next, an appropriate hash size is selected by the user. This value is typically a power of two, and can range from 2^12 to 2^30 depending on the number of unique factor levels one would like to represent. Then, modulo division is performed on the hashed representation using the specified hash size as the divisor and the hashed value as the dividend. The remainder of this computation is then used to assign the hashed feature to a “bucket,” which is now represented as a number.</p>

<p>For example, if the hashed value for “movies” is 35 and the hash size is 2^2, after doing modulo division (in R: 35 %% 4) we end up with a value of 3 (there are 2^2 – 1 (0,1,2,3) possible buckets for the remainder). The feature “movies” is now represented as a dummy variable 3. Finally, the model is trained normally using these numbers to represent the hashed factor levels.</p>

<h1 id="advantages-and-disadvantages-of-feature-hashing">Advantages and disadvantages of feature hashing</h1>

<p>There are several benefits to using this technique. First, it saves memory because instead of potentially creating hundreds or thousands of dummy variables using strings as the feature names, we are now only using numeric representations of text—which can be represented more efficiently. Also, the effect of hashing means we can reduce the number of unique factor levels to any arbitrary size. For instance, we could map 1000 unique factor levels to 10 buckets if desired.</p>

<p>This advantage is also a potential weak point of the method: if we use a hash size that is too small, we will end up with hash collisions, whereby different factor levels end up being mapped to the same bucket. Most of the time this does not significantly affect predictive performance, but it could if two contradictory factor levels happened to be put into the same bucket. As an illustration, if “movies” and “television” were mapped to the same bucket this would likely be OK; but if the levels “Satanic rock” and “Christian rock” were mapped to the same bucket, then the resulting feature would lose any interpretable meaning since we could not be sure whether the feature’s weight in the model was due to the effect of Satanic rock or Christian rock. The good news is that by choosing an appropriately large hash size we can reduce the chance of such unfortunate collisions from occurring. But again, the major drawback is that by converting our factor levels into numbers, we no longer have the ability to gauge variable importance, or understand exactly how different variables contribute to the model’s predictions.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">FeatureHashing</span><span class="p">)</span><span class="w">
</span><span class="n">df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">read.csv</span><span class="p">(</span><span class="s1">'kick_sample.csv'</span><span class="p">,</span><span class="w"> </span><span class="n">stringsAsFactors</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">F</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w"> </span><span class="c1">#BREAKUP INTO TRAINING AND TESTING</span><span class="w">
</span><span class="n">set.seed</span><span class="p">(</span><span class="m">1</span><span class="p">)</span><span class="w">
</span><span class="n">sp</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">createDataPartition</span><span class="p">(</span><span class="n">df</span><span class="o">$</span><span class="n">backers</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="o">=</span><span class="m">.8</span><span class="p">,</span><span class="w"> </span><span class="n">list</span><span class="o">=</span><span class="kc">FALSE</span><span class="p">)</span><span class="w">
</span><span class="n">train</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">df</span><span class="p">[</span><span class="n">sp</span><span class="p">,]</span><span class="w">
</span><span class="n">test</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">df</span><span class="p">[</span><span class="o">-</span><span class="n">sp</span><span class="p">,]</span><span class="w">
</span></code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">prep_fun</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
  </span><span class="n">x</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> 
    </span><span class="c1"># make text lower case</span><span class="w">
    </span><span class="n">str_to_lower</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> 
    </span><span class="c1"># remove non-alphanumeric symbols</span><span class="w">
    </span><span class="n">str_replace_all</span><span class="p">(</span><span class="s2">"[^[:alpha:]]"</span><span class="p">,</span><span class="w"> </span><span class="s2">" "</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> 
    </span><span class="c1"># collapse multiple spaces</span><span class="w">
    </span><span class="n">str_replace_all</span><span class="p">(</span><span class="s2">"\\s+"</span><span class="p">,</span><span class="w"> </span><span class="s2">" "</span><span class="p">)</span><span class="w">
</span><span class="p">}</span><span class="w">
</span><span class="c1">#prep_fun = tolower</span><span class="w">
</span><span class="n">tok_fun</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">word_tokenizer</span><span class="w">

</span><span class="c1">#try to fix foreign characters</span><span class="w">
</span><span class="n">df</span><span class="o">$</span><span class="n">name</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">iconv</span><span class="p">(</span><span class="n">df</span><span class="o">$</span><span class="n">name</span><span class="p">,</span><span class="w"> </span><span class="s1">'Latin-9'</span><span class="p">)</span><span class="w">

</span><span class="c1">#create training iterator</span><span class="w">
</span><span class="n">it_train</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">itoken</span><span class="p">(</span><span class="n">train</span><span class="o">$</span><span class="n">name</span><span class="p">,</span><span class="w"> 
                  </span><span class="n">preprocessor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prep_fun</span><span class="p">,</span><span class="w"> 
                  </span><span class="n">tokenizer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tok_fun</span><span class="p">,</span><span class="w"> 
                  </span><span class="n">progressbar</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w">
</span><span class="n">stop_words</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="n">tm</span><span class="o">::</span><span class="n">stopwords</span><span class="p">(</span><span class="s1">'en'</span><span class="p">),</span><span class="s2">"i"</span><span class="p">,</span><span class="w"> </span><span class="s2">"me"</span><span class="p">,</span><span class="w"> </span><span class="s2">"my"</span><span class="p">,</span><span class="w"> </span><span class="s2">"myself"</span><span class="p">,</span><span class="w"> 
               </span><span class="s2">"we"</span><span class="p">,</span><span class="w"> </span><span class="s2">"our"</span><span class="p">,</span><span class="w"> </span><span class="s2">"ours"</span><span class="p">,</span><span class="w"> </span><span class="s2">"ourselves"</span><span class="p">,</span><span class="w"> </span><span class="s2">"you"</span><span class="p">,</span><span class="w"> </span><span class="s2">"your"</span><span class="p">,</span><span class="w"> </span><span class="s2">"yours"</span><span class="p">,</span><span class="w">
               </span><span class="s1">'a'</span><span class="p">,</span><span class="w"> </span><span class="s1">'the'</span><span class="p">,</span><span class="w"> </span><span class="s1">'for'</span><span class="p">,</span><span class="w"> </span><span class="s1">'of'</span><span class="p">,</span><span class="w"> </span><span class="s1">'and'</span><span class="p">,</span><span class="w"> </span><span class="s1">'in'</span><span class="p">,</span><span class="w"> </span><span class="s1">'to'</span><span class="p">,</span><span class="w"> </span><span class="s1">'act'</span><span class="p">,</span><span class="w"> </span><span class="s1">'s'</span><span class="p">)</span><span class="w">

</span><span class="c1">#we'll use up to trigrams here</span><span class="w">
</span><span class="n">vocab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">create_vocabulary</span><span class="p">(</span><span class="n">it_train</span><span class="p">,</span><span class="w"> </span><span class="n">ngram</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">),</span><span class="w"> </span><span class="n">stopwords</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">stop_words</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#we keep 500 words max. this is already pushing memory limits of R</span><span class="w">
</span><span class="n">pruned_vocab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prune_vocabulary</span><span class="p">(</span><span class="n">vocab</span><span class="p">,</span><span class="w"> 
           
                   </span><span class="n">term_count_min</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">10</span><span class="p">,</span><span class="w">
                                </span><span class="n">vocab_term_max</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">500</span><span class="p">)</span><span class="w"> 

</span><span class="c1">#keep &lt;- which(nchar(pruned_vocab$term) &gt; 1)</span><span class="w">
</span><span class="c1">#pruned_vocab &lt;- pruned_vocab[keep,]</span><span class="w">
</span><span class="n">vectorizer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">vocab_vectorizer</span><span class="p">(</span><span class="n">pruned_vocab</span><span class="p">)</span><span class="w">

</span><span class="c1">#create training dtm</span><span class="w">
</span><span class="n">dtm_train</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="n">create_dtm</span><span class="p">(</span><span class="n">it_train</span><span class="p">,</span><span class="w"> </span><span class="n">vectorizer</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Now rinse and repeat for the test set</span><span class="w">
</span><span class="n">it_test</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">itoken</span><span class="p">(</span><span class="n">test</span><span class="o">$</span><span class="n">name</span><span class="p">,</span><span class="w"> 
                  </span><span class="n">preprocessor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prep_fun</span><span class="p">,</span><span class="w"> 
                  </span><span class="n">tokenizer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tok_fun</span><span class="p">,</span><span class="w"> 
                  </span><span class="n">progressbar</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w">
</span><span class="n">stop_words</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="n">tm</span><span class="o">::</span><span class="n">stopwords</span><span class="p">(</span><span class="s1">'en'</span><span class="p">),</span><span class="s2">"i"</span><span class="p">,</span><span class="w"> </span><span class="s2">"me"</span><span class="p">,</span><span class="w"> </span><span class="s2">"my"</span><span class="p">,</span><span class="w"> </span><span class="s2">"myself"</span><span class="p">,</span><span class="w"> 
               </span><span class="s2">"we"</span><span class="p">,</span><span class="w"> </span><span class="s2">"our"</span><span class="p">,</span><span class="w"> </span><span class="s2">"ours"</span><span class="p">,</span><span class="w"> </span><span class="s2">"ourselves"</span><span class="p">,</span><span class="w"> </span><span class="s2">"you"</span><span class="p">,</span><span class="w"> </span><span class="s2">"your"</span><span class="p">,</span><span class="w"> </span><span class="s2">"yours"</span><span class="p">,</span><span class="w">
               </span><span class="s1">'a'</span><span class="p">,</span><span class="w"> </span><span class="s1">'the'</span><span class="p">,</span><span class="w"> </span><span class="s1">'for'</span><span class="p">,</span><span class="w"> </span><span class="s1">'of'</span><span class="p">,</span><span class="w"> </span><span class="s1">'and'</span><span class="p">,</span><span class="w"> </span><span class="s1">'in'</span><span class="p">,</span><span class="w"> </span><span class="s1">'to'</span><span class="p">,</span><span class="w"> </span><span class="s1">'act'</span><span class="p">,</span><span class="w"> </span><span class="s1">'s'</span><span class="p">)</span><span class="w">

</span><span class="n">vocab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">create_vocabulary</span><span class="p">(</span><span class="n">it_test</span><span class="p">,</span><span class="w"> </span><span class="n">ngram</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">),</span><span class="w"> </span><span class="n">stopwords</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">stop_words</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#do dtm for test set</span><span class="w">
</span><span class="n">dtm_test</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">create_dtm</span><span class="p">(</span><span class="n">it_test</span><span class="p">,</span><span class="w"> </span><span class="n">vectorizer</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#should be same number of columns</span><span class="w">
</span><span class="nf">dim</span><span class="p">(</span><span class="n">dtm_test</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 9999  500
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">dim</span><span class="p">(</span><span class="n">dtm_train</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 40001   500
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#create tf idf instance. apply to train then transform test based on it</span><span class="w">
</span><span class="n">model_tfidf</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">TfIdf</span><span class="o">$</span><span class="n">new</span><span class="p">()</span><span class="w">

</span><span class="c1">#USE THESE SINCE DCGMATRIX OBJECTS</span><span class="w">
</span><span class="c1">#fit tfidf based on train</span><span class="w">
</span><span class="n">dtm_tfidf_train</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model_tfidf</span><span class="o">$</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">dtm_train</span><span class="p">)</span><span class="w">

</span><span class="c1">#use train tfidf to transform test</span><span class="w">
</span><span class="n">dtm_tfidf_test</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model_tfidf</span><span class="o">$</span><span class="n">transform</span><span class="p">(</span><span class="n">dtm_test</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#COMBINE WITH NON CATEGORICAL FEATURES. We will feature hash the cats</span><span class="w">
</span><span class="c1">##COMBINE WITH ORIGINAL FEATURES</span><span class="w">
</span><span class="n">full_tr</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">cbind</span><span class="p">(</span><span class="n">dtm_tfidf_train</span><span class="p">,</span><span class="w"> </span><span class="n">train</span><span class="o">$</span><span class="n">goal</span><span class="p">,</span><span class="w"> </span><span class="n">train</span><span class="o">$</span><span class="n">word_count</span><span class="p">,</span><span class="w"> </span><span class="n">train</span><span class="o">$</span><span class="n">total_chars</span><span class="p">,</span><span class="w"> </span><span class="n">train</span><span class="o">$</span><span class="n">exc_count</span><span class="p">,</span><span class="w">
                 </span><span class="n">train</span><span class="o">$</span><span class="n">yr_deadline</span><span class="p">,</span><span class="w"> </span><span class="n">train</span><span class="o">$</span><span class="n">mo_deadline</span><span class="p">,</span><span class="w"> </span><span class="n">train</span><span class="o">$</span><span class="n">extreme</span><span class="p">)</span><span class="w">

</span><span class="c1">#only needed for xgboost</span><span class="w">
</span><span class="n">target</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">train</span><span class="o">$</span><span class="n">backers</span><span class="w">
</span><span class="nf">dim</span><span class="p">(</span><span class="n">full_tr</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 40001   507
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Create full test set by combining original features back</span><span class="w">
</span><span class="n">full_ts</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">cbind</span><span class="p">(</span><span class="n">dtm_tfidf_test</span><span class="p">,</span><span class="w"> </span><span class="n">test</span><span class="o">$</span><span class="n">goal</span><span class="p">,</span><span class="w"> </span><span class="n">test</span><span class="o">$</span><span class="n">word_count</span><span class="p">,</span><span class="w"> </span><span class="n">test</span><span class="o">$</span><span class="n">total_chars</span><span class="p">,</span><span class="w"> 
                 </span><span class="n">test</span><span class="o">$</span><span class="n">exc_count</span><span class="p">,</span><span class="w"> </span><span class="n">test</span><span class="o">$</span><span class="n">yr_deadline</span><span class="p">,</span><span class="w"> </span><span class="n">test</span><span class="o">$</span><span class="n">mo_deadline</span><span class="p">,</span><span class="w"> </span><span class="n">test</span><span class="o">$</span><span class="n">extreme</span><span class="p">)</span><span class="w">
</span><span class="n">target_ts</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">test</span><span class="o">$</span><span class="n">backers</span><span class="w">
</span></code></pre></div></div>
<h3 id="with-feature-hashing-its-easy-to-include-interactions-among-categories">With feature hashing it’s easy to include interactions among categories</h3>

<p>Now we will consider all possible two way interactions among factor variables in our dataset</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#create all 2 way interactions among factor variables</span><span class="w">
</span><span class="n">f</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="p">(</span><span class="n">category</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">main_category</span><span class="w"> </span><span class="o">+</span><span class="n">currency</span><span class="w"> </span><span class="o">+</span><span class="n">country</span><span class="p">)</span><span class="o">^</span><span class="m">2</span><span class="w">
          
</span></code></pre></div></div>

<p>For now, we will construct 2^19 (524,288) features for these combinations of factor levels. Then we will add the 500 text features to get 524,789 total feature columns. A dataset with dimensions 40000 x 524789 would take up far too much RAM were it stored in a data frame. That’s why we need to use sparse matrices.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">FeatureHashing</span><span class="p">)</span><span class="w">
</span><span class="c1">#hash for factor levels in training</span><span class="w">
</span><span class="n">tr_hash</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">hashed.model.matrix</span><span class="p">(</span><span class="n">f</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="o">=</span><span class="n">train</span><span class="p">,</span><span class="w"> </span><span class="n">hash.size</span><span class="o">=</span><span class="m">2</span><span class="o">^</span><span class="m">19</span><span class="p">,</span><span class="w"> </span><span class="n">transpose</span><span class="o">=</span><span class="kc">FALSE</span><span class="p">,</span><span class="w"> </span><span class="n">create.mapping</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w">

</span><span class="c1">#view examples of factor interactions</span><span class="w">
</span><span class="n">hash.mapping</span><span class="p">(</span><span class="n">tr_hash</span><span class="p">)[</span><span class="m">1</span><span class="o">:</span><span class="m">5</span><span class="p">]</span><span class="w">
</span></code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>##             categoryArt:countryNL main_categoryPublishing:countryLU 
##                             82092                             36139 
##         categoryDrama:currencyDKK       categoryWebseries:countryDE 
##                            215718                            378480 
##  categoryGraphic Design:countryCA 
##                            512448
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#pass this to training</span><span class="w">
</span><span class="n">dtm_full_tr</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">cbind</span><span class="p">(</span><span class="n">full_tr</span><span class="p">,</span><span class="w"> </span><span class="n">tr_hash</span><span class="p">)</span><span class="w">

</span><span class="n">target_tr</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">train</span><span class="o">$</span><span class="n">backers</span><span class="w">
</span><span class="nf">dim</span><span class="p">(</span><span class="n">dtm_full_tr</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1]  40001 524795
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#hash for factor levels in testing</span><span class="w">
</span><span class="n">ts_hash</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">hashed.model.matrix</span><span class="p">(</span><span class="n">f</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="o">=</span><span class="n">test</span><span class="p">,</span><span class="w"> </span><span class="n">hash.size</span><span class="o">=</span><span class="m">2</span><span class="o">^</span><span class="m">19</span><span class="p">,</span><span class="w"> </span><span class="n">transpose</span><span class="o">=</span><span class="kc">FALSE</span><span class="p">)</span><span class="w">

</span><span class="c1">#combine</span><span class="w">
</span><span class="n">dtm_full_ts</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">cbind</span><span class="p">(</span><span class="n">full_ts</span><span class="p">,</span><span class="w"> </span><span class="n">ts_hash</span><span class="p">)</span><span class="w">
</span><span class="n">target_ts</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">test</span><span class="o">$</span><span class="n">backers</span><span class="w">
</span><span class="nf">dim</span><span class="p">(</span><span class="n">dtm_full_ts</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1]   9999 524795
</code></pre></div></div>

<p>If you want to pass in sparse matrices you can’t use a formula, instead we need to use the x/y interface. This will also not auto-create dummy vars for us the way the formula interface does. We’ll use this instead of the adaptive cross validation we used earlier. Caret doesn’t work nicely with sparse matrices here for some reason.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">glmnet</span><span class="p">)</span><span class="w">

</span><span class="c1">#Use 5 fold CV</span><span class="w">
</span><span class="n">set.seed</span><span class="p">(</span><span class="m">1</span><span class="p">)</span><span class="w">
</span><span class="n">glm_model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">cv.glmnet</span><span class="p">(</span><span class="n">dtm_full_tr</span><span class="p">,</span><span class="w"> </span><span class="n">target_tr</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">.1</span><span class="p">,</span><span class="w"> </span><span class="m">.5</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">),</span><span class="w"> </span><span class="n">lambda</span><span class="o">=</span><span class="n">seq</span><span class="p">(</span><span class="m">0.00001</span><span class="p">,</span><span class="m">1000</span><span class="p">,</span><span class="w"> </span><span class="m">10</span><span class="p">),</span><span class="w"> 
                     </span><span class="n">family</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"gaussian"</span><span class="p">,</span><span class="w"> </span><span class="n">type.measure</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"mse"</span><span class="p">,</span><span class="w"> </span><span class="n">nfolds</span><span class="o">=</span><span class="m">5</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p>To save time we will use the original function from the glmnet package. We didn’t use the previous adaptive resampling procedure simply because model training took too long.</p>

<h1 id="compare-predictions">Compare predictions</h1>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#GET PREDICTIONS</span><span class="w">
</span><span class="n">prd</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">data.frame</span><span class="p">(</span><span class="n">predictions_glm</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">predict</span><span class="p">(</span><span class="n">glm_model</span><span class="p">,</span><span class="w"> </span><span class="n">dtm_full_ts</span><span class="p">,</span><span class="w"> </span><span class="n">s</span><span class="o">=</span><span class="s2">"lambda.min"</span><span class="p">),</span><span class="w">
                  </span><span class="n">predictions_xg</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">predict</span><span class="p">(</span><span class="n">xg_model</span><span class="p">,</span><span class="w"> </span><span class="n">dtm_full_ts</span><span class="p">),</span><span class="w">
                  </span><span class="n">actuals</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">target_ts</span><span class="p">)</span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">dplyr</span><span class="o">::</span><span class="n">rename</span><span class="p">(</span><span class="s1">'predictions_glm'</span><span class="o">=</span><span class="n">X</span><span class="m">1</span><span class="p">)</span><span class="w">

</span><span class="c1">#Set negative predictions to 0</span><span class="w">
</span><span class="n">prd</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">prd</span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">mutate</span><span class="p">(</span><span class="n">predictions_glm</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ifelse</span><span class="p">(</span><span class="n">predictions_glm</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">predictions_glm</span><span class="p">))</span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">mutate</span><span class="p">(</span><span class="n">predictions_xg</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ifelse</span><span class="p">(</span><span class="n">predictions_xg</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">predictions_xg</span><span class="p">))</span><span class="w">

</span><span class="c1">#calculate rmse GLMNET</span><span class="w">
</span><span class="n">rmse</span><span class="p">(</span><span class="n">prd</span><span class="o">$</span><span class="n">actuals</span><span class="p">,</span><span class="w"> </span><span class="n">prd</span><span class="o">$</span><span class="n">predictions_glm</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 1416.422
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#calculate rmse XGBOOST</span><span class="w">
</span><span class="n">rmse</span><span class="p">(</span><span class="n">prd</span><span class="o">$</span><span class="n">actuals</span><span class="p">,</span><span class="w"> </span><span class="n">prd</span><span class="o">$</span><span class="n">predictions_xg</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 1388.013
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#check against training mean</span><span class="w">
</span><span class="n">rmse</span><span class="p">(</span><span class="n">prd</span><span class="o">$</span><span class="n">actuals</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">train</span><span class="o">$</span><span class="n">backers</span><span class="p">))</span><span class="w">
</span></code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 1419.206
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#plot both on top </span><span class="w">
</span><span class="n">prd</span><span class="o">%&gt;%</span><span class="w">
</span><span class="n">ggplot</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">actuals</span><span class="p">,</span><span class="w"> </span><span class="n">predictions_glm</span><span class="p">))</span><span class="o">+</span><span class="w">
  </span><span class="n">geom_point</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="m">.2</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">)</span><span class="o">+</span><span class="w">
  </span><span class="n">geom_point</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">actuals</span><span class="p">,</span><span class="w"> </span><span class="n">predictions_xg</span><span class="p">),</span><span class="n">size</span><span class="o">=</span><span class="m">1</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="m">.2</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">)</span><span class="o">+</span><span class="w">
  </span><span class="n">geom_abline</span><span class="p">(</span><span class="n">slope</span><span class="o">=</span><span class="m">1</span><span class="p">)</span><span class="o">+</span><span class="w">
  </span><span class="n">scale_x_log10</span><span class="p">()</span><span class="o">+</span><span class="w">
  </span><span class="n">scale_y_log10</span><span class="p">()</span><span class="o">+</span><span class="w">
  </span><span class="n">labs</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">'Feature Hashed Data'</span><span class="p">,</span><span class="w"> </span><span class="n">subtitle</span><span class="o">=</span><span class="s1">'Glmnet (blue) vs. xgBoost (red)'</span><span class="p">)</span><span class="o">+</span><span class="w">
  </span><span class="n">theme_minimal</span><span class="p">()</span><span class="w">
</span></code></pre></div></div>

<p><img src="finalreport_files/figure-markdown_github/unnamed-chunk-39-1.png" alt="" /></p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#density plot</span><span class="w">
</span><span class="n">prd</span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">gather</span><span class="p">()</span><span class="o">%&gt;%</span><span class="w">
</span><span class="n">ggplot</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">value</span><span class="p">,</span><span class="n">fill</span><span class="o">=</span><span class="n">key</span><span class="p">))</span><span class="o">+</span><span class="w">
  </span><span class="n">geom_density</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="m">.5</span><span class="p">)</span><span class="o">+</span><span class="w">
  </span><span class="n">scale_x_log10</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="n">scales</span><span class="o">::</span><span class="n">comma</span><span class="p">)</span><span class="o">+</span><span class="w">
  </span><span class="n">labs</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">'Feature Hashing'</span><span class="p">,</span><span class="w"> </span><span class="n">subtitle</span><span class="o">=</span><span class="s1">'Glmnet (green) vs. xgBoost (blue) vs. Actual (red)'</span><span class="p">)</span><span class="o">+</span><span class="w">
  </span><span class="n">theme_minimal</span><span class="p">()</span><span class="w">
</span></code></pre></div></div>

<p><img src="finalreport_files/figure-markdown_github/unnamed-chunk-39-2.png" alt="" /></p>

<h3 id="feature-hashing-results">Feature hashing results</h3>
<p>Once we begin to feature hash, the power of xgboost begins to shine. We can see from the chart above that the xgboost predictions seem to do a much better job at replicating the outcome distribution in the test set. Meanwhile, the glm model seems to just predict around the training set mean, with a few higher predictions–probably based on certain categorical factors.
Overall feature hashing gives a very modest performance boost only to the xgboost model.</p>

<h1 id="strategy-4-string-distance-based-grouping">Strategy 4: String distance based grouping</h1>

<p>I first learned about this creative approach through Manuel Amunategui’s <a href="https://amunategui.github.io/stringdist/">blog post</a>. This technique borrows from the field of computational linguistics and combines two seemingly unrelated data mining methods to automate the problem of manually grouping related factor levels. The major benefit of this method is that it does not require any special domain knowledge in order to produce fairly robust groupings of categories. All the grouping is done on the basis of the characteristics of the words used as categories.</p>

<p>The method proceeds as follows. First, string distance is computed using any one of the many string distance metrics: Levenshtein, Jaro-Winkler, Hamming, etc. Typically, these metrics are computed by taking two strings (usually short strings which keep the number of permutations reasonable) and then performing several actions on this pair: insertion, deletion, substitution, and transposition of adjacent characters. The goal is to determine how many actions are needed in order to transform one string into another. For each of these four actions, each metric assigns some cost value. The sum of these costs is the distance between the strings.</p>

<p>As a very general example, imagine computing the string distance of the words kitten and sitting. First we could substitute the k for an s. Then we could substitute the e with an i. Then, finally, we could insert a g at the end to make kitten become sitting. These three actions and their associated cost will allow us to compute the distance between the strings.</p>

<p>Once a distance matrix for all pairs of strings has been computed, then typically an agglomerative clustering algorithm is used to combine the words into a pre-defined number of clusters k. This method works by iteratively merging the nearest cluster objects together until there is one final cluster of all objects.</p>

<h2 id="downsides-to-string-distance-clustering">Downsides to string distance clustering</h2>

<p>One downside to this method is that selecting k (the desired number of clusters) is left up to the analyst and that depending on the string distance metric chosen and the linkage criterion used, different clusters will arise. For example, using the maximum or minimum distance between elements of two clusters will result in clusters being merged in different orders during the agglomeration process.</p>

<p>There are further downsides to this method. Firstly, it does not scale well to categorical features with more than approximately 15,000 unique factor levels. This is because the memory needed to store the distance matrix grows exponentially. So it is possible analysts will first need to manually group some values before using this method in cases where there are many thousands of unique values. Secondly, we run into the problem of nested model bias again (i.e., information leakage) due to the fact we first need to combine training and test sets in order to assign clusters to the strings. This means that our training clusters and therefore our model was built using information contained in the test set and thus we should be wary of its performance on the test set, since some information in the test set was actually used to train the model. Test set performance may thus be overly optimistic.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">stringdist</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">caret</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">tidyverse</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">tm</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">tidytext</span><span class="p">)</span><span class="w">
</span><span class="n">df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">read.csv</span><span class="p">(</span><span class="s1">'kick_sample.csv'</span><span class="p">,</span><span class="w"> </span><span class="n">stringsAsFactors</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">F</span><span class="p">)</span><span class="w">

</span><span class="c1">#collapse categories into 100 Unique ones to reduce complexity</span><span class="w">
</span><span class="c1">#</span><span class="w">
</span><span class="n">df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">df</span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">mutate</span><span class="p">(</span><span class="n">new_cat</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fct_lump</span><span class="p">(</span><span class="n">category</span><span class="p">,</span><span class="w"> </span><span class="m">100</span><span class="p">))</span><span class="w">

 </span><span class="c1">#BREAKUP INTO TRAINING AND TESTING. Do after clustering. </span><span class="w">
</span><span class="n">set.seed</span><span class="p">(</span><span class="m">1</span><span class="p">)</span><span class="w">
</span><span class="n">sp</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">createDataPartition</span><span class="p">(</span><span class="n">df</span><span class="o">$</span><span class="n">backers</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="o">=</span><span class="m">.8</span><span class="p">,</span><span class="w"> </span><span class="n">list</span><span class="o">=</span><span class="kc">FALSE</span><span class="p">)</span><span class="w">
</span><span class="n">train</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">df</span><span class="p">[</span><span class="n">sp</span><span class="p">,]</span><span class="w">
</span><span class="n">test</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">df</span><span class="p">[</span><span class="o">-</span><span class="n">sp</span><span class="p">,]</span><span class="w">
</span></code></pre></div></div>

<h1 id="step-1-pasting-categories-together">Step 1: Pasting categories together</h1>

<p>We see that we now have 1804 unique categories once we combine the four categorical columns. You can paste as many character columns together as you want. Here we paste together the text of four columns into one long string.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">textclean</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">tidytext</span><span class="p">)</span><span class="w">

</span><span class="n">df</span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">mutate</span><span class="p">(</span><span class="n">new_cat</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">paste0</span><span class="p">(</span><span class="n">main_category</span><span class="p">,</span><span class="w"> </span><span class="n">category</span><span class="p">,</span><span class="w"> </span><span class="n">currency</span><span class="p">,</span><span class="w"> </span><span class="n">country</span><span class="p">))</span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">select</span><span class="p">(</span><span class="n">new_cat</span><span class="p">)</span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">unique</span><span class="p">()</span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">pull</span><span class="p">()</span><span class="o">%&gt;%</span><span class="w">
  </span><span class="nf">length</span><span class="p">()</span><span class="w">
</span></code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 1804
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Examine 10 examples of categories we'll use to cluster</span><span class="w">
</span><span class="n">df</span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">mutate</span><span class="p">(</span><span class="n">new_cat</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">paste0</span><span class="p">(</span><span class="n">main_category</span><span class="p">,</span><span class="w"> </span><span class="n">category</span><span class="p">,</span><span class="w"> </span><span class="n">currency</span><span class="p">,</span><span class="w"> </span><span class="n">country</span><span class="p">))</span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">select</span><span class="p">(</span><span class="n">new_cat</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>##                                new_cat
## 1              PublishingAcademicUSDUS
## 2                      MusicMusicGBPGB
## 3              PhotographyAnimalsUSDUS
## 4          PhotographyPhotographyUSDUS
## 5                        FoodFoodEURDE
## 6            DesignProduct DesignUSDUS
## 7                          ArtArtUSDUS
## 8             GamesTabletop GamesUSDUS
## 9             GamesTabletop GamesUSDUS
## 10                FoodFood TrucksEURAT
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#finally perform transformation of new pasted strings</span><span class="w">
</span><span class="c1">#delete old columns</span><span class="w">
</span><span class="n">df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">df</span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">mutate</span><span class="p">(</span><span class="n">new_cat</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">paste0</span><span class="p">(</span><span class="n">main_category</span><span class="p">,</span><span class="w"> </span><span class="n">category</span><span class="p">,</span><span class="w"> </span><span class="n">currency</span><span class="p">,</span><span class="w"> </span><span class="n">country</span><span class="p">),</span><span class="w">
         </span><span class="n">main_category</span><span class="o">=</span><span class="w"> </span><span class="kc">NULL</span><span class="p">,</span><span class="w">
         </span><span class="n">category</span><span class="o">=</span><span class="kc">NULL</span><span class="p">,</span><span class="w">
         </span><span class="n">currency</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">NULL</span><span class="p">,</span><span class="w">
         </span><span class="n">country</span><span class="o">=</span><span class="kc">NULL</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<h1 id="step-2-generate-a-distance-matrix-of-strings">Step 2: Generate a distance matrix of strings</h1>

<p>Now we take these 1804 unique category levels and calculate string distance based on Jaro-Winkler distance.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dis_full</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">stringdistmatrix</span><span class="p">(</span><span class="n">unique</span><span class="p">(</span><span class="n">df</span><span class="o">$</span><span class="n">new_cat</span><span class="p">)</span><span class="w">
</span><span class="p">,</span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"jw"</span><span class="p">,</span><span class="n">useNames</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">'strings'</span><span class="p">)</span><span class="w">

</span><span class="n">hc</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">hclust</span><span class="p">(</span><span class="n">as.dist</span><span class="p">(</span><span class="n">dis_full</span><span class="p">),</span><span class="w"> </span><span class="s1">'ward.D'</span><span class="p">)</span><span class="w">

</span><span class="c1">#Plot is too chaotic to really read</span><span class="w">
</span><span class="n">plot</span><span class="p">(</span><span class="n">hc</span><span class="p">,</span><span class="w"> </span><span class="n">cex</span><span class="o">=</span><span class="m">.01</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p><img src="finalreport_files/figure-markdown_github/unnamed-chunk-42-1.png" alt="" /></p>

<p>At this point you will need to experiment. In the interest of time, we will only cluster on 10 categories. But it would be worth your time to see how the predictive performance varies as you change the number of clusters from 10 to say, 100.</p>
<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Here we decide on how many clusters we want. Let's try 10</span><span class="w">
</span><span class="n">df_clust</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">data.frame</span><span class="p">(</span><span class="n">category</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">unique</span><span class="p">(</span><span class="n">df</span><span class="o">$</span><span class="n">new_cat</span><span class="p">),</span><span class="w"> </span><span class="n">cluster</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cutree</span><span class="p">(</span><span class="n">hc</span><span class="p">,</span><span class="w"> </span><span class="n">k</span><span class="o">=</span><span class="m">10</span><span class="p">),</span><span class="w">
                       </span><span class="n">stringsAsFactors</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">F</span><span class="p">)</span><span class="w">

</span><span class="c1">#In order to see what's happening here let's make a visual</span><span class="w">
</span><span class="n">df_clust</span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">group_by</span><span class="p">(</span><span class="n">cluster</span><span class="p">)</span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">sample_frac</span><span class="p">(</span><span class="m">.05</span><span class="p">)</span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">mutate</span><span class="p">(</span><span class="n">group_row</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">row_number</span><span class="p">(</span><span class="n">cluster</span><span class="p">))</span><span class="o">%&gt;%</span><span class="w">
  </span><span class="c1">#filter(group_row &lt; 200)%&gt;%</span><span class="w">
  </span><span class="n">ggplot</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">cluster</span><span class="p">,</span><span class="w"> </span><span class="n">group_row</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="o">=</span><span class="n">factor</span><span class="p">(</span><span class="n">cluster</span><span class="p">)))</span><span class="o">+</span><span class="w">
  </span><span class="n">geom_text</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">label</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">category</span><span class="p">),</span><span class="w"> </span><span class="n">size</span><span class="o">=</span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="m">.8</span><span class="p">,</span><span class="w"> </span><span class="n">position</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">position_jitter</span><span class="p">(</span><span class="n">height</span><span class="o">=</span><span class="m">100</span><span class="p">))</span><span class="o">+</span><span class="w">
  </span><span class="n">guides</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="kc">FALSE</span><span class="p">)</span><span class="o">+</span><span class="w">
  </span><span class="n">scale_x_continuous</span><span class="p">(</span><span class="n">breaks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">seq</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">50</span><span class="p">),</span><span class="w"> </span><span class="n">labels</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">seq</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">50</span><span class="p">,</span><span class="m">1</span><span class="p">))</span><span class="o">+</span><span class="w">
  </span><span class="n">theme_minimal</span><span class="p">()</span><span class="o">+</span><span class="w">
  </span><span class="n">labs</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">'category clusters k = 10'</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="o">=</span><span class="s1">'cluster'</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="o">=</span><span class="s1">''</span><span class="p">)</span><span class="o">+</span><span class="w">
  </span><span class="n">theme</span><span class="p">(</span><span class="n">axis.text.y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">element_blank</span><span class="p">(),</span><span class="w">
        </span><span class="n">panel.grid.major</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">element_blank</span><span class="p">(),</span><span class="w">
        </span><span class="n">panel.grid.minor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">element_blank</span><span class="p">())</span><span class="w">
</span></code></pre></div></div>

<p><img src="finalreport_files/figure-markdown_github/unnamed-chunk-42-2.png" alt="" /> From this sampled version of the cluster assignments we can get a feel for what is happening in each cluster. For example, cluster 4 seems to be food categories and cluster 10 seems to be about technology.</p>

<h2 id="step-3-joining-cluster-assignments-to-original-data">Step 3: Joining cluster assignments to original data</h2>

<p>Now we join back the cluster assignments to the original dataframe and use the cluster assignment in lieu of the actual string level.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">df</span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">inner_join</span><span class="p">(</span><span class="n">df_clust</span><span class="p">,</span><span class="w"> </span><span class="n">by</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="s1">'new_cat'</span><span class="o">=</span><span class="s1">'category'</span><span class="p">))</span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">mutate</span><span class="p">(</span><span class="n">cluster</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">as.factor</span><span class="p">(</span><span class="n">cluster</span><span class="p">))</span><span class="w">
</span><span class="n">glimpse</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## Observations: 50,000
## Variables: 13
## $ name          &lt;chr&gt; "3 great ways to have a big income with no  form...
## $ backers       &lt;int&gt; 0, 51, 136, 0, 3, 30, 0, 6, 232, 2, 170, 104, 1,...
## $ goal          &lt;dbl&gt; 5000.00, 7855.97, 2200.00, 5000.00, 29296.76, 20...
## $ dow_deadline  &lt;chr&gt; "Sun", "Wed", "Sun", "Fri", "Sun", "Sat", "Mon",...
## $ yr_deadline   &lt;int&gt; 2015, 2017, 2014, 2014, 2016, 2012, 2017, 2017, ...
## $ mo_deadline   &lt;int&gt; 7, 10, 11, 8, 9, 6, 4, 6, 5, 9, 11, 10, 7, 3, 10...
## $ word_count    &lt;int&gt; 11, 1, 2, 6, 7, 7, 3, 5, 10, 8, 8, 5, 10, 1, 6, ...
## $ ave_sentiment &lt;dbl&gt; 0.22613350, 0.00000000, 0.00000000, 0.00000000, ...
## $ total_chars   &lt;int&gt; 59, 8, 22, 28, 40, 57, 31, 31, 57, 49, 44, 33, 6...
## $ exc_count     &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...
## $ extreme       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...
## $ new_cat       &lt;chr&gt; "PublishingAcademicUSDUS", "MusicMusicGBPGB", "P...
## $ cluster       &lt;fct&gt; 1, 2, 3, 3, 4, 5, 2, 6, 6, 4, 7, 8, 9, 9, 9, 5, ...
</code></pre></div></div>

<p>You can now see the cluster assignments for each observation.</p>

<h1 id="now-go-back-and-prepare-text-features-as-usual">Now go back and prepare text features as usual</h1>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">text2vec</span><span class="p">)</span><span class="w">
</span><span class="n">prep_fun</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
  </span><span class="n">x</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> 
    </span><span class="c1"># make text lower case</span><span class="w">
    </span><span class="n">str_to_lower</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> 
    </span><span class="c1"># remove non-alphanumeric symbols</span><span class="w">
    </span><span class="n">str_replace_all</span><span class="p">(</span><span class="s2">"[^[:alpha:]]"</span><span class="p">,</span><span class="w"> </span><span class="s2">" "</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> 
    </span><span class="c1"># collapse multiple spaces</span><span class="w">
    </span><span class="n">str_replace_all</span><span class="p">(</span><span class="s2">"\\s+"</span><span class="p">,</span><span class="w"> </span><span class="s2">" "</span><span class="p">)</span><span class="w">
</span><span class="p">}</span><span class="w">
</span><span class="c1">#prep_fun = tolower</span><span class="w">
</span><span class="n">tok_fun</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">word_tokenizer</span><span class="w">

</span><span class="c1">#try to fix foreign characters</span><span class="w">
</span><span class="n">df</span><span class="o">$</span><span class="n">name</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">iconv</span><span class="p">(</span><span class="n">df</span><span class="o">$</span><span class="n">name</span><span class="p">,</span><span class="w"> </span><span class="s1">'Latin-9'</span><span class="p">)</span><span class="w">

</span><span class="c1">#create training iterator</span><span class="w">
</span><span class="n">it_train</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">itoken</span><span class="p">(</span><span class="n">train</span><span class="o">$</span><span class="n">name</span><span class="p">,</span><span class="w"> 
                  </span><span class="n">preprocessor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prep_fun</span><span class="p">,</span><span class="w"> 
                  </span><span class="n">tokenizer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tok_fun</span><span class="p">,</span><span class="w"> 
                  </span><span class="n">progressbar</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w">
</span><span class="n">stop_words</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="n">tm</span><span class="o">::</span><span class="n">stopwords</span><span class="p">(</span><span class="s1">'en'</span><span class="p">),</span><span class="s2">"i"</span><span class="p">,</span><span class="w"> </span><span class="s2">"me"</span><span class="p">,</span><span class="w"> </span><span class="s2">"my"</span><span class="p">,</span><span class="w"> </span><span class="s2">"myself"</span><span class="p">,</span><span class="w"> 
               </span><span class="s2">"we"</span><span class="p">,</span><span class="w"> </span><span class="s2">"our"</span><span class="p">,</span><span class="w"> </span><span class="s2">"ours"</span><span class="p">,</span><span class="w"> </span><span class="s2">"ourselves"</span><span class="p">,</span><span class="w"> </span><span class="s2">"you"</span><span class="p">,</span><span class="w"> </span><span class="s2">"your"</span><span class="p">,</span><span class="w"> </span><span class="s2">"yours"</span><span class="p">,</span><span class="w">
               </span><span class="s1">'a'</span><span class="p">,</span><span class="w"> </span><span class="s1">'the'</span><span class="p">,</span><span class="w"> </span><span class="s1">'for'</span><span class="p">,</span><span class="w"> </span><span class="s1">'of'</span><span class="p">,</span><span class="w"> </span><span class="s1">'and'</span><span class="p">,</span><span class="w"> </span><span class="s1">'in'</span><span class="p">,</span><span class="w"> </span><span class="s1">'to'</span><span class="p">,</span><span class="w"> </span><span class="s1">'act'</span><span class="p">,</span><span class="w"> </span><span class="s1">'s'</span><span class="p">)</span><span class="w">

</span><span class="c1">#we'll use up to trigrams here</span><span class="w">
</span><span class="n">vocab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">create_vocabulary</span><span class="p">(</span><span class="n">it_train</span><span class="p">,</span><span class="w"> </span><span class="n">ngram</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">),</span><span class="w"> </span><span class="n">stopwords</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">stop_words</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#we keep 500 words max. this is already pushing memory limits of R</span><span class="w">
</span><span class="n">pruned_vocab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prune_vocabulary</span><span class="p">(</span><span class="n">vocab</span><span class="p">,</span><span class="w"> 
                                </span><span class="n">term_count_min</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">10</span><span class="p">,</span><span class="w">
                                </span><span class="n">vocab_term_max</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">500</span><span class="p">)</span><span class="w"> 

</span><span class="c1">#keep &lt;- which(nchar(pruned_vocab$term) &gt; 1)</span><span class="w">
</span><span class="c1">#pruned_vocab &lt;- pruned_vocab[keep,]</span><span class="w">
</span><span class="n">vectorizer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">vocab_vectorizer</span><span class="p">(</span><span class="n">pruned_vocab</span><span class="p">)</span><span class="w">

</span><span class="c1">#create training dtm</span><span class="w">
</span><span class="n">dtm_train</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="n">create_dtm</span><span class="p">(</span><span class="n">it_train</span><span class="p">,</span><span class="w"> </span><span class="n">vectorizer</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">it_test</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">itoken</span><span class="p">(</span><span class="n">test</span><span class="o">$</span><span class="n">name</span><span class="p">,</span><span class="w"> 
                  </span><span class="n">preprocessor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prep_fun</span><span class="p">,</span><span class="w"> 
                  </span><span class="n">tokenizer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tok_fun</span><span class="p">,</span><span class="w"> 
                  </span><span class="n">progressbar</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w">
</span><span class="n">stop_words</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="n">tm</span><span class="o">::</span><span class="n">stopwords</span><span class="p">(</span><span class="s1">'en'</span><span class="p">),</span><span class="s2">"i"</span><span class="p">,</span><span class="w"> </span><span class="s2">"me"</span><span class="p">,</span><span class="w"> </span><span class="s2">"my"</span><span class="p">,</span><span class="w"> </span><span class="s2">"myself"</span><span class="p">,</span><span class="w"> 
               </span><span class="s2">"we"</span><span class="p">,</span><span class="w"> </span><span class="s2">"our"</span><span class="p">,</span><span class="w"> </span><span class="s2">"ours"</span><span class="p">,</span><span class="w"> </span><span class="s2">"ourselves"</span><span class="p">,</span><span class="w"> </span><span class="s2">"you"</span><span class="p">,</span><span class="w"> </span><span class="s2">"your"</span><span class="p">,</span><span class="w"> </span><span class="s2">"yours"</span><span class="p">,</span><span class="w">
               </span><span class="s1">'a'</span><span class="p">,</span><span class="w"> </span><span class="s1">'the'</span><span class="p">,</span><span class="w"> </span><span class="s1">'for'</span><span class="p">,</span><span class="w"> </span><span class="s1">'of'</span><span class="p">,</span><span class="w"> </span><span class="s1">'and'</span><span class="p">,</span><span class="w"> </span><span class="s1">'in'</span><span class="p">,</span><span class="w"> </span><span class="s1">'to'</span><span class="p">,</span><span class="w"> </span><span class="s1">'act'</span><span class="p">,</span><span class="w"> </span><span class="s1">'s'</span><span class="p">)</span><span class="w">

</span><span class="n">vocab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">create_vocabulary</span><span class="p">(</span><span class="n">it_test</span><span class="p">,</span><span class="w"> </span><span class="n">ngram</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">),</span><span class="w"> </span><span class="n">stopwords</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">stop_words</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#do dtm for test set</span><span class="w">
</span><span class="n">dtm_test</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">create_dtm</span><span class="p">(</span><span class="n">it_test</span><span class="p">,</span><span class="w"> </span><span class="n">vectorizer</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#should be same number of columns</span><span class="w">
</span><span class="nf">dim</span><span class="p">(</span><span class="n">dtm_test</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 9999  500
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">dim</span><span class="p">(</span><span class="n">dtm_train</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 40001   500
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#create tf idf instance. apply to train then transform test based on it</span><span class="w">
</span><span class="n">model_tfidf</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">TfIdf</span><span class="o">$</span><span class="n">new</span><span class="p">()</span><span class="w">

</span><span class="c1">#USE THESE SINCE DCGMATRIX OBJECTS</span><span class="w">
</span><span class="c1">#fit tfidf based on train</span><span class="w">
</span><span class="n">dtm_tfidf_train</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model_tfidf</span><span class="o">$</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">dtm_train</span><span class="p">)</span><span class="w">

</span><span class="c1">#use train tfidf to transform test</span><span class="w">
</span><span class="n">dtm_tfidf_test</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model_tfidf</span><span class="o">$</span><span class="n">transform</span><span class="p">(</span><span class="n">dtm_test</span><span class="p">)</span><span class="w">

 </span><span class="n">dtm_full</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">as.data.frame</span><span class="p">(</span><span class="n">as.matrix</span><span class="p">(</span><span class="n">dtm_tfidf_train</span><span class="p">),</span><span class="w"> </span><span class="n">stringsAsFactors</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">F</span><span class="p">)</span><span class="w">
 </span><span class="n">dtm_full_test</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">as.data.frame</span><span class="p">(</span><span class="n">as.matrix</span><span class="p">(</span><span class="n">dtm_tfidf_test</span><span class="p">),</span><span class="w"> </span><span class="n">stringsAsFactors</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">F</span><span class="p">)</span><span class="w">

</span><span class="nf">dim</span><span class="p">(</span><span class="n">dtm_full</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 40001   500
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#now get rid of "name" column before dividing back into train test</span><span class="w">
</span><span class="c1">#YOU CANNOT USE CHARS IF CBIND WITH MATRIX! CONVERT TO FACTOR First</span><span class="w">
</span><span class="n">train</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">train</span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">mutate</span><span class="p">(</span><span class="n">dow_deadline</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">as.factor</span><span class="p">(</span><span class="n">dow_deadline</span><span class="p">))</span><span class="w">
</span><span class="n">test</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">test</span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">mutate</span><span class="p">(</span><span class="n">dow_deadline</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">as.factor</span><span class="p">(</span><span class="n">dow_deadline</span><span class="p">))</span><span class="w">


</span><span class="c1">#COMBINE BACK WITH ORIGINAL FEATURES. now 515 features</span><span class="w">
</span><span class="n">full_train</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">cbind</span><span class="p">(</span><span class="n">dtm_tfidf_train</span><span class="p">,</span><span class="w"> </span><span class="n">train</span><span class="o">$</span><span class="n">goal</span><span class="p">,</span><span class="w">
                    </span><span class="n">train</span><span class="o">$</span><span class="n">dow_deadline</span><span class="p">,</span><span class="w"> </span><span class="n">train</span><span class="o">$</span><span class="n">yr_deadline</span><span class="p">,</span><span class="w">
                    </span><span class="n">train</span><span class="o">$</span><span class="n">mo_deadline</span><span class="p">,</span><span class="w"> </span><span class="n">train</span><span class="o">$</span><span class="n">word_count</span><span class="p">,</span><span class="w">
                    </span><span class="n">train</span><span class="o">$</span><span class="n">ave_sentiment</span><span class="p">,</span><span class="w"> </span><span class="n">train</span><span class="o">$</span><span class="n">total_chars</span><span class="p">,</span><span class="w">
                    </span><span class="n">train</span><span class="o">$</span><span class="n">exc_count</span><span class="p">,</span><span class="w"> </span><span class="n">train</span><span class="o">$</span><span class="n">extreme</span><span class="p">,</span><span class="w">
                    </span><span class="n">train</span><span class="o">$</span><span class="n">cluster</span><span class="p">)</span><span class="w">

</span><span class="n">train_targ</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">train</span><span class="o">$</span><span class="n">backers</span><span class="w">

</span><span class="n">full_test</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">cbind</span><span class="p">(</span><span class="n">dtm_tfidf_test</span><span class="p">,</span><span class="w"> </span><span class="n">test</span><span class="o">$</span><span class="n">goal</span><span class="p">,</span><span class="w">
                    </span><span class="n">test</span><span class="o">$</span><span class="n">dow_deadline</span><span class="p">,</span><span class="w"> </span><span class="n">test</span><span class="o">$</span><span class="n">yr_deadline</span><span class="p">,</span><span class="w">
                    </span><span class="n">test</span><span class="o">$</span><span class="n">mo_deadline</span><span class="p">,</span><span class="w"> </span><span class="n">test</span><span class="o">$</span><span class="n">word_count</span><span class="p">,</span><span class="w">
                    </span><span class="n">test</span><span class="o">$</span><span class="n">ave_sentiment</span><span class="p">,</span><span class="w"> </span><span class="n">test</span><span class="o">$</span><span class="n">total_chars</span><span class="p">,</span><span class="w">
                    </span><span class="n">test</span><span class="o">$</span><span class="n">exc_count</span><span class="p">,</span><span class="w"> </span><span class="n">test</span><span class="o">$</span><span class="n">extreme</span><span class="p">,</span><span class="w">
                    </span><span class="n">test</span><span class="o">$</span><span class="n">cluster</span><span class="p">)</span><span class="w">
</span><span class="n">test_targ</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">test</span><span class="o">$</span><span class="n">backers</span><span class="w">


</span><span class="c1">#word is same as column name. need make unique! common error</span><span class="w">
</span><span class="n">colnames</span><span class="p">(</span><span class="n">full_train</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">make.unique</span><span class="p">(</span><span class="n">colnames</span><span class="p">(</span><span class="n">full_train</span><span class="p">))</span><span class="w">
</span><span class="n">colnames</span><span class="p">(</span><span class="n">full_test</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">make.unique</span><span class="p">(</span><span class="n">colnames</span><span class="p">(</span><span class="n">full_test</span><span class="p">))</span><span class="w">

</span><span class="n">rm</span><span class="p">(</span><span class="n">dtm_full</span><span class="p">)</span><span class="w">
</span><span class="n">rm</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span><span class="w">
</span><span class="n">rm</span><span class="p">(</span><span class="n">dtm_test</span><span class="p">)</span><span class="w">
</span><span class="n">rm</span><span class="p">(</span><span class="n">dtm_tfidf_test</span><span class="p">)</span><span class="w">
</span><span class="n">rm</span><span class="p">(</span><span class="n">dtm_tfidf_train</span><span class="p">)</span><span class="w">
</span><span class="n">rm</span><span class="p">(</span><span class="n">dtm_train</span><span class="p">)</span><span class="w">
</span><span class="n">rm</span><span class="p">(</span><span class="n">dtm_full_test</span><span class="p">)</span><span class="w">
</span><span class="n">gc</span><span class="p">()</span><span class="w">
</span></code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>##            used  (Mb) gc trigger  (Mb)  max used   (Mb)
## Ncells  3625491 193.7    5613254 299.8   5613254  299.8
## Vcells 24305721 185.5  128628637 981.4 160785751 1226.7
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#SET UP FOLDS WITHIN TRAINING SET</span><span class="w">
</span><span class="n">set.seed</span><span class="p">(</span><span class="m">123</span><span class="p">)</span><span class="w">
</span><span class="c1"># myFolds &lt;- createFolds(full_train$backers, k=5)</span><span class="w">

</span><span class="c1"># Create reusable trainControl object: myControl</span><span class="w">
</span><span class="n">control</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">trainControl</span><span class="p">(</span><span class="w">
  </span><span class="n">method</span><span class="o">=</span><span class="s1">'adaptive_cv'</span><span class="p">,</span><span class="w"> </span><span class="n">number</span><span class="o">=</span><span class="m">5</span><span class="p">,</span><span class="w">
  </span><span class="n">verboseIter</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,</span><span class="w">
  </span><span class="c1">#index=myFolds,</span><span class="w">
  </span><span class="n">preProcOptions</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"nzv"</span><span class="p">,</span><span class="w"> </span><span class="s2">"center"</span><span class="p">,</span><span class="w"> </span><span class="s2">"scale"</span><span class="p">,</span><span class="w"> </span><span class="s2">"pca"</span><span class="p">),</span><span class="w">
  </span><span class="n">returnData</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">,</span><span class="w">
   </span><span class="n">adaptive</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">min</span><span class="o">=</span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="m">0.1</span><span class="p">,</span><span class="w"> </span><span class="n">method</span><span class="o">=</span><span class="s1">'gls'</span><span class="p">,</span><span class="w"> </span><span class="n">complete</span><span class="o">=</span><span class="kc">FALSE</span><span class="p">,</span><span class="w"> </span><span class="n">search</span><span class="o">=</span><span class="s1">'random'</span><span class="p">)</span><span class="w">
  </span><span class="c1">#savePredictions = 'final'</span><span class="w">
</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p>Interestingly, glmnet seems to train faster using the x/y input instead of the formula input.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">set.seed</span><span class="p">(</span><span class="m">1</span><span class="p">)</span><span class="w">
</span><span class="n">glm_model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">train</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">full_train</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="o">=</span><span class="n">train_targ</span><span class="p">,</span><span class="w"> </span><span class="n">method</span><span class="o">=</span><span class="s1">'glmnet'</span><span class="p">,</span><span class="w"> </span><span class="n">metric</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"RMSE"</span><span class="p">,</span><span class="w"> </span><span class="n">trControl</span><span class="o">=</span><span class="n">control</span><span class="p">)</span><span class="w">

</span><span class="c1">#faster xg</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">xgboost</span><span class="p">)</span><span class="w">
</span><span class="n">set.seed</span><span class="p">(</span><span class="m">1</span><span class="p">)</span><span class="w">
</span><span class="n">xg_model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">xgboost</span><span class="p">(</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">full_train</span><span class="p">,</span><span class="w"> 
                     </span><span class="n">label</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">train_targ</span><span class="p">,</span><span class="w"> 
                     </span><span class="n">lambda</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w">
                     </span><span class="n">alpha</span><span class="o">=</span><span class="m">1</span><span class="p">,</span><span class="w">
                    </span><span class="n">nfold</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">5</span><span class="p">,</span><span class="w">
                     </span><span class="n">max.depth</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">4</span><span class="p">,</span><span class="w"> </span><span class="c1">#more for more complicated interactions</span><span class="w">
                     </span><span class="n">eta</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">.1</span><span class="p">,</span><span class="w"> </span><span class="n">nthread</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> 
                     </span><span class="n">nrounds</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">600</span><span class="p">,</span><span class="w"> </span><span class="n">params</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">booster</span><span class="o">=</span><span class="s1">'gbtree'</span><span class="p">),</span><span class="w"> </span><span class="c1">#lower max depth raise nrounds</span><span class="w">
                     </span><span class="n">objective</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"reg:linear"</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<h1 id="compare-predictions-1">Compare predictions</h1>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">Metrics</span><span class="p">)</span><span class="w">
</span><span class="c1">#GET PREDICTIONS</span><span class="w">
</span><span class="n">prd</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">data.frame</span><span class="p">(</span><span class="n">predictions_glm</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">predict</span><span class="p">(</span><span class="n">glm_model</span><span class="p">,</span><span class="w"> </span><span class="n">full_test</span><span class="p">),</span><span class="w">
                  </span><span class="n">predictions_xg</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">predict</span><span class="p">(</span><span class="n">xg_model</span><span class="p">,</span><span class="w"> </span><span class="n">full_test</span><span class="p">),</span><span class="w">
                  </span><span class="n">actuals</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">test_targ</span><span class="p">)</span><span class="w">
</span><span class="n">prd</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">prd</span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">mutate</span><span class="p">(</span><span class="n">predictions_xg</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ifelse</span><span class="p">(</span><span class="n">predictions_xg</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">predictions_xg</span><span class="p">),</span><span class="w">
         </span><span class="n">predictions_glm</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ifelse</span><span class="p">(</span><span class="n">predictions_glm</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">predictions_glm</span><span class="p">))</span><span class="w">

</span><span class="c1">#calculate rmse GLMNET</span><span class="w">
</span><span class="n">rmse</span><span class="p">(</span><span class="n">prd</span><span class="o">$</span><span class="n">actuals</span><span class="p">,</span><span class="w"> </span><span class="n">prd</span><span class="o">$</span><span class="n">predictions_glm</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 1419.361
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#calculate rmse xg</span><span class="w">
</span><span class="n">rmse</span><span class="p">(</span><span class="n">prd</span><span class="o">$</span><span class="n">actuals</span><span class="p">,</span><span class="w"> </span><span class="n">prd</span><span class="o">$</span><span class="n">predictions_xg</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 1376.957
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#check against training mean</span><span class="w">
</span><span class="n">rmse</span><span class="p">(</span><span class="n">prd</span><span class="o">$</span><span class="n">actuals</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">train</span><span class="o">$</span><span class="n">backers</span><span class="p">))</span><span class="w">
</span></code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 1419.206
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#plot both on top </span><span class="w">
</span><span class="n">prd</span><span class="o">%&gt;%</span><span class="w">
</span><span class="n">ggplot</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">actuals</span><span class="m">+1</span><span class="p">,</span><span class="w"> </span><span class="n">predictions_glm</span><span class="m">+1</span><span class="p">))</span><span class="o">+</span><span class="w">
  </span><span class="n">geom_point</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="m">.2</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">)</span><span class="o">+</span><span class="w">
  </span><span class="n">geom_point</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">actuals</span><span class="m">+1</span><span class="p">,</span><span class="w"> </span><span class="n">predictions_xg</span><span class="m">+1</span><span class="p">),</span><span class="n">size</span><span class="o">=</span><span class="m">1</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="m">.2</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">)</span><span class="o">+</span><span class="w">
  </span><span class="n">geom_abline</span><span class="p">(</span><span class="n">slope</span><span class="o">=</span><span class="m">1</span><span class="p">)</span><span class="o">+</span><span class="w">
  </span><span class="n">scale_x_log10</span><span class="p">()</span><span class="o">+</span><span class="w">
  </span><span class="n">scale_y_log10</span><span class="p">()</span><span class="o">+</span><span class="w">
  </span><span class="n">labs</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">'Naive top 10'</span><span class="p">,</span><span class="w"> </span><span class="n">subtitle</span><span class="o">=</span><span class="s1">'Glmnet (blue) vs. xgBoost (red)'</span><span class="p">)</span><span class="o">+</span><span class="w">
  </span><span class="n">theme_minimal</span><span class="p">()</span><span class="o">+</span><span class="w">
  </span><span class="n">theme</span><span class="p">(</span><span class="n">axis.title.y</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="n">element_blank</span><span class="p">())</span><span class="w">
</span></code></pre></div></div>

<p><img src="finalreport_files/figure-markdown_github/unnamed-chunk-50-1.png" alt="" /></p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#density plot</span><span class="w">
</span><span class="n">prd</span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">gather</span><span class="p">()</span><span class="o">%&gt;%</span><span class="w">
</span><span class="n">ggplot</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">value</span><span class="m">+1</span><span class="p">,</span><span class="n">fill</span><span class="o">=</span><span class="n">key</span><span class="p">))</span><span class="o">+</span><span class="w">
  </span><span class="n">geom_density</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="m">.5</span><span class="p">)</span><span class="o">+</span><span class="w">
  </span><span class="n">scale_x_log10</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="n">scales</span><span class="o">::</span><span class="n">comma</span><span class="p">)</span><span class="o">+</span><span class="w">
  </span><span class="n">labs</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">'Naive top 10'</span><span class="p">,</span><span class="w"> </span><span class="n">subtitle</span><span class="o">=</span><span class="s1">'Glmnet (green) vs. xgBoost (blue) vs. Actual (red)'</span><span class="p">)</span><span class="o">+</span><span class="w">
  </span><span class="n">theme_minimal</span><span class="p">()</span><span class="w">
</span></code></pre></div></div>

<p><img src="finalreport_files/figure-markdown_github/unnamed-chunk-50-2.png" alt="" /></p>

<h3 id="string-distance-clustering-results">String distance clustering results</h3>
<p>Here we see again limitations in the elastic net. Most predictions are right at the training set mean, with very little variance. However the xgboost predictions do a pretty good job of catching campaigns that have very few backers. This is reflected in the best overall RMSE of 1376.957. Remember that our original xgboost test set RMSE (no special processing) was around 1413, so this represents about a 2.6% reduction in RMSE by using the string clusters.</p>

<p><img src="./pics/res.png" alt="results" class="img-responsive" /></p>

<p>Overall, the performance of both models on these data was less than impressive. In many cases the Glmnet model could barely predict better than simply guessing the training set mean. The xgBoost algorithm performed slightly better, but its performance was also not particularly promising. These results imply that there is simply too much noise in this dataset. To test this hunch, I trained the same models but did not include any of the 500 text features. The results were more or less exactly the same, with or without them. It looks like trying our goal of trying to predict the number of backers using the text features is too difficult a task for our relatively simple approaches. It would be interesting to see how a deep-learning model with feature hashing or string distance clustering would perform.</p>

<p>Though this particular experiment did not show any benefit for a simple ‘top n collapsing’ approach, I have seen small performance boosts when using other datasets.
It seems that tree-based methods are more likely to show this benefit as well. Glmnet performance doesn’t seem to change. In other tests I’ve done, the improvement due is not large, but the effort required to do so is also not large. However, one must be careful to make sure that the training/testing sets contain the same levels; otherwise, one may still encounter the issue of novel levels in the testing set.</p>

<p>Impact coding had no discernible effect on the test set RMSE. Nevertheless, this method is still useful because of the way it automatically handles missing values, novel test set levels, and also can help with feature selection (using significance threshold pruning). It would be worth trying this technique out on other datasets to see if there are indeed some performance improvements.</p>

<p>The best performing method used string distance clustering, using just 10 clusters (from a possible 223 unique factor levels). There was about a 3% reduction in RMSE over the control condition. Nevertheless, the performance may be slightly optimistic due to the problem of “nested model bias” explained above. The clusters were in fact formed using observations from the training and test set, so we should not be totally surprised when the performance evaluation on the test set is slightly better than other methods (which did not rely on information from the test set).</p>

<p>Feature hashing is unfortunately not a magic bullet, though it did improve predictions slightly for the tree-based model. This result would seem to corroborate the idea that this particular dataset simply does not contain enough signal. I am still convinced that this method is extremely useful when building models using real-world—and often messy—datasets. Almost every Python submission on Kaggle uses some kind of feature hashing nowadays, so surely there must be some benefit to it.
Though we must trade off model interpretability, I think the gains in terms of model training time and the ability to easily model hundreds or thousands of interaction terms, makes feature hashing an essentially skill for any data analyst.</p>
<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p>Micci-Barreca, Daniele. “A preprocessing scheme for high-cardinality categorical attributes in classification and prediction problems.” ACM SIGKDD Explorations Newsletter 3.1 (2001): 27-32. <a href="#fnref:1" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:2">
      <p>Mount, John, and Nina Zumel. “The vtreat R package: a statistically sound data processor for predictive modeling.” <a href="#fnref:2" class="reversefootnote">&#8617;</a> <a href="#fnref:2:1" class="reversefootnote">&#8617;<sup>2</sup></a> <a href="#fnref:2:2" class="reversefootnote">&#8617;<sup>3</sup></a></p>
    </li>
  </ol>
</div>
